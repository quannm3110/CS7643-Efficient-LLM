{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20382,"status":"ok","timestamp":1714008501765,"user":{"displayName":"Marcel Man","userId":"12296236785080944914"},"user_tz":-480},"id":"tx7_kmDqNGwq","outputId":"715096bb-d194-4bd7-8c49-4d3a30e70061"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1714008502361,"user":{"displayName":"Marcel Man","userId":"12296236785080944914"},"user_tz":-480},"id":"Xu36X7TX29Eb","outputId":"fb6d2d00-c2f7-4a5d-b533-ac4a5dbc3f11"},"outputs":[{"output_type":"stream","name":"stdout","text":["               total        used        free      shared  buff/cache   available\n","Mem:            12Gi       725Mi       8.0Gi       1.0Mi       4.0Gi        11Gi\n","Swap:             0B          0B          0B\n","Thu Apr 25 01:28:20 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   60C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","GPU 0: Tesla T4 (UUID: GPU-50acd5f7-40c4-3030-dfd5-161d7e147402)\n"]}],"source":["# Free colab seems to give different amount of general RAM to different users or even the same users at different times.\n","!free -h\n","\n","# check which nvidia drivers and cuda version is running\n","!nvidia-smi\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":80729,"status":"ok","timestamp":1714008583087,"user":{"displayName":"Marcel Man","userId":"12296236785080944914"},"user_tz":-480},"id":"ZpL2uwCnODEY","outputId":"cf19b5ec-088a-4960-dbe3-8f5157139bd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n","Requirement already satisfied: torch==2.2.1+cu121 in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: torchvision==0.17.1+cu121 in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n","Requirement already satisfied: torchaudio==2.2.1+cu121 in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1+cu121)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1+cu121)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1+cu121)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (2.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.1+cu121) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.1+cu121) (9.4.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1+cu121)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1+cu121) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1+cu121) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["# need to match the system-wide installed cuda-11 for deepspeed to compile\n","# so install the matching pytorch\n","\n","# pt-1.8.1 works too\n","# !pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","# pt-1.11\n","#!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n","\n","!pip install torch==2.2.1+cu121 torchvision==0.17.1+cu121 torchaudio==2.2.1+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39005,"status":"ok","timestamp":1714008622067,"user":{"displayName":"Marcel Man","userId":"12296236785080944914"},"user_tz":-480},"id":"F3BEur1nRsJ8","outputId":"643cc5f9-f543-462f-8a27-b2a9735b4970"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/microsoft/deepspeed\n","  Cloning https://github.com/microsoft/deepspeed to /tmp/pip-req-build-qvkz91m8\n","  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/deepspeed /tmp/pip-req-build-qvkz91m8\n","  Resolved https://github.com/microsoft/deepspeed to commit fa8458b1a80d6ba55091b17f092de19bbf95eb3d\n","  Running command git submodule update --init --recursive -q\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting hjson (from deepspeed==0.14.3+fa8458b1)\n","  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ninja (from deepspeed==0.14.3+fa8458b1)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3+fa8458b1) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3+fa8458b1) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3+fa8458b1) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3+fa8458b1) (9.0.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3+fa8458b1) (2.7.0)\n","Collecting pynvml (from deepspeed==0.14.3+fa8458b1)\n","  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3+fa8458b1) (2.2.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3+fa8458b1) (4.66.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.3+fa8458b1) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.3+fa8458b1) (2.18.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.3+fa8458b1) (4.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (3.13.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.3+fa8458b1) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.14.3+fa8458b1) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed==0.14.3+fa8458b1) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed==0.14.3+fa8458b1) (1.3.0)\n","Building wheels for collected packages: deepspeed\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.14.3+fa8458b1-py3-none-any.whl size=1437477 sha256=f9f914a425242056491ed2ec0292379cb530359b012514aba13ff621b5468db0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-w8jqfx7q/wheels/c7/2a/60/6cd1be5e9093337b6243efab085ade35b787b5c4c1aaf99387\n","Successfully built deepspeed\n","Installing collected packages: ninja, hjson, pynvml, deepspeed\n","Successfully installed deepspeed-0.14.3+fa8458b1 hjson-3.1.0 ninja-1.11.1.1 pynvml-11.5.0\n"]}],"source":["# either install the release\n","#!pip install deepspeed\n","# or the master\n","!pip install git+https://github.com/microsoft/deepspeed\n","\n","# remove any previously cached deepspeed objects as they can be incompatible with this new build\n","#!rm -r /root/.cache/torch_extensions/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43603,"status":"ok","timestamp":1714008665649,"user":{"displayName":"Marcel Man","userId":"12296236785080944914"},"user_tz":-480},"id":"pcxd8zEPOd_N","outputId":"a62f0bdc-de3b-4b70-e460-418b898c077a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n","Collecting evaluate==0.3.0\n","  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2.19.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (1.25.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (0.70.16)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (0.22.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (24.0)\n","Collecting responses<0.19 (from evaluate==0.3.0)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (3.13.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (3.9.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.3.0) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0) (2024.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.3.0) (1.16.0)\n","Installing collected packages: responses, evaluate\n","Successfully installed evaluate-0.3.0 responses-0.18.0\n","Collecting transformers==4.30.0\n","  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2024.2.2)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.40.0\n","    Uninstalling transformers-4.40.0:\n","      Successfully uninstalled transformers-4.40.0\n","Successfully installed tokenizers-0.13.3 transformers-4.30.0\n","Collecting accelerate==0.27.2\n","  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (0.22.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.27.2) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.27.2) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.27.2\n"]}],"source":["!pip install datasets\n","!pip install evaluate==0.3.0\n","!pip install transformers==4.30.0\n","!pip install accelerate==0.27.2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2437,"status":"ok","timestamp":1714008668071,"user":{"displayName":"Marcel Man","userId":"12296236785080944914"},"user_tz":-480},"id":"dGOBukj1anK1","outputId":"5c5972f7-5454-4ce7-bb21-a6ee9e3c0e70"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","True\n"]}],"source":["import torch\n","print(torch.cuda.device_count())\n","print(torch.cuda.is_available())"]},{"cell_type":"code","source":["# ICL experiment (original)\n","# bash $PROJECT_DIR/scripts/in_context/mnli/run_gpt3.sh mnli 16 facebook/opt-30b 1 60000\n","# Train custom model\n","#!python eval.py --task_name mnli --num_shots 2 --model_name_or_path facebook/opt-125m --pattern \"{text1} {text2} ?\" --target_prefix \" \" --target_tokens \"ĠYes,ĠNo\" --separate_shots_by \"\\n\\n\" --group \"minimal\" --max_seq_length 2048 --output_dir \"./output\" --do_eval --eval_task_name \"hans\" --per_device_eval_batch_size 10 --balanced --shuffle --seed 0 --data_seed 0 --dataset_cache_dir \"./hf_dataset\" --cache_dir \"./hf_model\" --report_to \"none\"\n","!python /content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft/eval.py \\\n","        --model_name_or_path facebook/opt-125m \\\n","        --cache_dir \"./hf_model\" \\\n","        --task_name mnli \\\n","        --pattern \"{text1} question: {text2} Yes or No?\" \\\n","        --target_prefix \" answer: \" \\\n","        --target_tokens \"ĠYes,ĠNo\" \\\n","        --separate_shots_by \"\\n\\n\" \\\n","        --group \"gpt-3\" \\\n","        --dataset_cache_dir \"./hf_dataset\" \\\n","        --max_seq_length 2048 \\\n","        --output_dir \"./output\" \\\n","        --do_eval  \\\n","        --eval_task_name \"hans\" \\\n","        --per_device_eval_batch_size 10 \\\n","        --num_shots 16 \\\n","        --balanced \\\n","        --shuffle \\\n","        --fp16 \\\n","        --seed 0 \\\n","        --data_seed 0 \\\n","        --report_to \"none\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6W9aRrx1CzLn","executionInfo":{"status":"ok","timestamp":1712503118243,"user_tz":-480,"elapsed":496523,"user":{"displayName":"Marcel Man","userId":"12296236785080944914"}},"outputId":"efb8ef36-b5e5-4bdd-fb5e-eab016c95ae7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-07 15:10:27.376151: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-07 15:10:27.376202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-07 15:10:27.510668: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-07 15:10:28.843337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[2024-04-07 15:10:37,429] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n","\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n","\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n","\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n","\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n","\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n","\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n","04/07/2024 15:10:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n","Downloading readme: 100% 35.3k/35.3k [00:00<00:00, 37.5MB/s]\n","Downloading data: 100% 52.2M/52.2M [00:04<00:00, 11.8MB/s]\n","Downloading data: 100% 1.21M/1.21M [00:00<00:00, 2.54MB/s]\n","Downloading data: 100% 1.25M/1.25M [00:00<00:00, 2.56MB/s]\n","Downloading data: 100% 1.22M/1.22M [00:01<00:00, 624kB/s]\n","Downloading data: 100% 1.26M/1.26M [00:00<00:00, 2.61MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 784803.00 examples/s]\n","Generating validation_matched split: 100% 9815/9815 [00:00<00:00, 763300.65 examples/s]\n","Generating validation_mismatched split: 100% 9832/9832 [00:00<00:00, 734040.53 examples/s]\n","Generating test_matched split: 100% 9796/9796 [00:00<00:00, 777610.85 examples/s]\n","Generating test_mismatched split: 100% 9847/9847 [00:00<00:00, 753852.40 examples/s]\n","Filter: 100% 392702/392702 [00:01<00:00, 216353.93 examples/s]\n","Filter: 100% 9815/9815 [00:00<00:00, 210850.55 examples/s]\n","Filter: 100% 9832/9832 [00:00<00:00, 205978.80 examples/s]\n","Filter: 100% 9796/9796 [00:00<00:00, 196052.94 examples/s]\n","Filter: 100% 9847/9847 [00:00<00:00, 207237.07 examples/s]\n","Map: 100% 261802/261802 [00:26<00:00, 10040.82 examples/s]\n","Map: 100% 6692/6692 [00:00<00:00, 12410.73 examples/s]\n","Map: 100% 6703/6703 [00:00<00:00, 12073.13 examples/s]\n","Map: 100% 9796/9796 [00:01<00:00, 9079.96 examples/s]\n","Map: 100% 9847/9847 [00:01<00:00, 7909.64 examples/s]\n","Casting the dataset: 100% 261802/261802 [00:00<00:00, 1353603.72 examples/s]\n","Casting the dataset: 100% 6692/6692 [00:00<00:00, 766913.91 examples/s]\n","Casting the dataset: 100% 6703/6703 [00:00<00:00, 789553.46 examples/s]\n","Casting the dataset: 100% 9796/9796 [00:00<00:00, 1046706.12 examples/s]\n","Casting the dataset: 100% 9847/9847 [00:00<00:00, 1062112.62 examples/s]\n","Downloading data: 100% 3.14M/3.14M [00:04<00:00, 747kB/s]\n","Downloading data: 100% 3.14M/3.14M [00:03<00:00, 958kB/s]\n","Generating train split: 100% 30000/30000 [00:00<00:00, 482753.13 examples/s]\n","Generating validation split: 100% 30000/30000 [00:00<00:00, 533531.43 examples/s]\n","Filter: 100% 30000/30000 [00:00<00:00, 83871.60 examples/s]\n","Filter: 100% 10000/10000 [00:00<00:00, 31423.61 examples/s]\n","Filter: 100% 10000/10000 [00:00<00:00, 32006.54 examples/s]\n","config.json: 100% 651/651 [00:00<00:00, 2.68MB/s]\n","tokenizer_config.json: 100% 685/685 [00:00<00:00, 4.43MB/s]\n","vocab.json: 100% 899k/899k [00:00<00:00, 1.13MB/s]\n","merges.txt: 100% 456k/456k [00:00<00:00, 683kB/s]\n","special_tokens_map.json: 100% 441/441 [00:00<00:00, 2.23MB/s]\n","pytorch_model.bin: 100% 251M/251M [00:05<00:00, 49.1MB/s]\n","generation_config.json: 100% 137/137 [00:00<00:00, 686kB/s]\n","{'entailment': 0, 'contradiction': 1}\n","{0: 'entailment', 1: 'contradiction'}\n","Filter: 100% 261802/261802 [00:02<00:00, 128762.07 examples/s]\n","Filter: 100% 261802/261802 [00:01<00:00, 154564.89 examples/s]\n","Filter: 100% 261802/261802 [00:01<00:00, 212417.29 examples/s]\n","[2, 1121, 5, 4619, 687, 4908, 15044, 6, 2782, 7373, 11047, 5, 3521, 9, 10332, 8, 34822, 1684, 1230, 782, 6, 8, 98, 5, 1947, 9, 2482, 22181, 8, 3713, 2457, 267, 1630, 5191, 4373, 11, 5, 76, 883, 612, 741, 4, 438, 4, 2156, 2351, 10, 25492, 190, 55, 3319, 87, 14, 9, 5, 30058, 1253, 54, 376, 423, 4, 864, 35, 20, 30058, 1253, 4209, 5, 36005, 25492, 14, 14344, 106, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 2895, 9, 5, 2261, 6, 19, 5, 8219, 9, 3516, 6, 54, 2282, 75, 648, 551, 10, 1413, 6, 67, 224, 14, 1402, 2189, 6, 217, 1131, 8, 613, 335, 6, 197, 28, 4371, 30, 2309, 4, 864, 35, 3516, 2282, 75, 551, 10, 1413, 15, 5, 696, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 42666, 99, 16, 110, 676, 57, 19, 101, 109, 47, 33, 7497, 6774, 14, 697, 19, 47, 50, 33, 3033, 19, 110, 1041, 50, 402, 101, 14, 864, 35, 3945, 70, 110, 6774, 1462, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1185, 581, 1819, 465, 10, 183, 18, 825, 7, 13830, 1671, 8907, 10, 182, 2814, 464, 31, 5, 16476, 2297, 1571, 9, 103, 9, 5, 1947, 3027, 4, 864, 35, 13830, 1671, 8907, 6822, 10, 2579, 5709, 7, 5, 81, 26195, 2297, 1571, 9, 97, 1947, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 24877, 1415, 62, 23, 123, 6, 5, 7705, 5764, 2227, 11, 69, 652, 4, 1437, 864, 35, 2708, 18, 652, 3491, 3195, 25, 79, 1415, 62, 23, 123, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 4297, 9574, 82, 82, 2025, 75, 14, 29804, 864, 35, 404, 82, 32, 2778, 29804, 4, 1437, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 9635, 1825, 6, 8963, 12, 2619, 17844, 73, 574, 25, 8316, 6335, 246, 4397, 3457, 19, 211, 4, 181, 7590, 1178, 341, 30389, 12, 9635, 16689, 620, 405, 13735, 514, 36, 30033, 864, 35, 20, 3457, 341, 1823, 12, 9635, 16689, 620, 405, 13735, 514, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 133, 3969, 694, 3827, 1030, 544, 13, 9473, 28207, 82, 54, 240, 244, 19, 35447, 4643, 6, 3469, 9531, 6, 8, 97, 284, 488, 3510, 4, 864, 35, 4619, 28207, 82, 58, 1286, 1030, 544, 30, 5, 3969, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 14541, 52, 4395, 75, 2120, 7, 4442, 5, 301, 9, 358, 1736, 4, 864, 35, 166, 197, 4442, 5, 301, 9, 358, 809, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 26724, 877, 16, 11401, 43709, 11835, 14, 38, 4036, 2598, 18118, 7, 3116, 1736, 33605, 16849, 13, 349, 3149, 9, 5, 1811, 5223, 7150, 5672, 9, 17450, 45248, 12, 31230, 6801, 1704, 12, 4310, 2691, 23149, 480, 102, 651, 14, 38, 23426, 8, 13, 61, 38, 1665, 25, 937, 4474, 4, 864, 35, 38, 1665, 25, 10, 937, 4474, 13, 10, 3228, 12, 33313, 651, 9, 1364, 4, 1437, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 1213, 439, 124, 8, 7264, 6, 5507, 19143, 6, 20752, 6, 10720, 6, 25609, 6, 8, 53, 2577, 19, 39, 28702, 4, 864, 35, 5507, 21, 634, 39, 34281, 8, 1730, 7, 908, 4, 1437, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 133, 138, 67, 1523, 10, 1186, 9, 4828, 8171, 1058, 6, 540, 4828, 12120, 6, 8, 14110, 12906, 5137, 1767, 4, 864, 35, 8575, 337, 8171, 1058, 16, 45, 65, 9, 5, 518, 1661, 30, 5, 138, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 13841, 1493, 115, 47, 2999, 159, 81, 68, 3248, 6, 151, 8, 697, 215, 10, 4267, 12, 3743, 8066, 116, 864, 35, 2612, 64, 75, 47, 697, 4558, 8, 146, 418, 396, 519, 23352, 70, 5, 86, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1708, 89, 24, 16, 6, 79, 64, 1137, 47, 1085, 72, 15966, 22, 1708, 596, 6, 313, 116, 1437, 864, 35, 125, 89, 24, 16, 6, 79, 34, 45, 11040, 7, 224, 4, 125, 596, 313, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 23007, 6073, 44444, 4, 864, 35, 44444, 227, 3806, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 3056, 939, 109, 24, 70, 1437, 37463, 4420, 939, 939, 860, 7, 1733, 37463, 37463, 10, 16090, 5671, 8, 864, 35, 38, 348, 393, 1381, 127, 865, 23, 10, 16090, 5671, 131, 16, 24, 543, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","2048\n","Casting the dataset: 100% 6692/6692 [00:00<00:00, 16026.84 examples/s]\n","Casting the dataset: 100% 5000/5000 [00:00<00:00, 10884.62 examples/s]\n","Casting the dataset: 100% 5000/5000 [00:00<00:00, 10616.97 examples/s]\n","Running tokenizer on dataset: 100% 6692/6692 [01:08<00:00, 98.31 examples/s] \n","Running tokenizer on dataset: 100% 5000/5000 [00:50<00:00, 98.26 examples/s] \n","Running tokenizer on dataset: 100% 5000/5000 [00:50<00:00, 98.46 examples/s]\n","Filter: 100% 6692/6692 [00:26<00:00, 253.93 examples/s]\n","Filter: 100% 5000/5000 [00:20<00:00, 249.00 examples/s]\n","Filter: 100% 5000/5000 [00:19<00:00, 256.64 examples/s]\n","  4% 30/670 [01:06<25:03,  2.35s/it]Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft/eval.py\", line 651, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft/eval.py\", line 591, in main\n","    outputs = trainer.predict(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3119, in predict\n","    output = eval_loop(\n","  File \"/content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft/ft_trainer.py\", line 1006, in evaluation_loop\n","    logits = self._pad_across_processes(logits)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3399, in _pad_across_processes\n","    size = torch.tensor(tensor.shape, device=tensor.device)[None]\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9rk40w0OPMi","executionInfo":{"status":"ok","timestamp":1712479857186,"user_tz":-480,"elapsed":4499148,"user":{"displayName":"Marcel Man","userId":"12296236785080944914"}},"outputId":"2ca228a6-1e29-4175-d2e5-c5f16340c0ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-04-07 07:36:05,707] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n","\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n","\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n","\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n","\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n","\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n","\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n","Sample 98 of the training set: {'premise': \"you know Uncle Sam but i've always thought that they were slow  as far as outside of the government you know\", 'hypothesis': \"My personal opinion is that they've always been fast.\", 'label': 1, 'idx': 93643, 'input_ids': [2, 6968, 216, 25848, 1960, 53, 939, 348, 460, 802, 14, 51, 58, 2635, 1437, 25, 444, 25, 751, 9, 5, 168, 47, 216, 1308, 1081, 2979, 16, 14, 51, 348, 460, 57, 1769, 4, 17487, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'soft_prompt_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_tokens': ['</s>', 'you', 'Ġknow', 'ĠUncle', 'ĠSam', 'Ġbut', 'Ġi', \"'ve\", 'Ġalways', 'Ġthought', 'Ġthat', 'Ġthey', 'Ġwere', 'Ġslow', 'Ġ', 'Ġas', 'Ġfar', 'Ġas', 'Ġoutside', 'Ġof', 'Ġthe', 'Ġgovernment', 'Ġyou', 'Ġknow', 'ĠMy', 'Ġpersonal', 'Ġopinion', 'Ġis', 'Ġthat', 'Ġthey', \"'ve\", 'Ġalways', 'Ġbeen', 'Ġfast', '.', 'Ġ?', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'input_text': \"</s>you know Uncle Sam but i've always thought that they were slow  as far as outside of the government you know My personal opinion is that they've always been fast.?<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\", 'label_text': 'contradiction'}.\n","Trainable parameters: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'score.dense.weight', 'score.dense.bias', 'score.output.weight', 'score.output.bias']\n","override self.deepspeed to False\n","{'eval_hans-lexical_overlap-entailment_loss': 0.8822359442710876, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0008, 'eval_hans-lexical_overlap-entailment_runtime': 59.3358, 'eval_hans-lexical_overlap-entailment_samples_per_second': 84.266, 'eval_hans-lexical_overlap-entailment_steps_per_second': 8.427, 'epoch': 1.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.5357074737548828, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9992, 'eval_hans-lexical_overlap-contradiction_runtime': 61.5255, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 81.267, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 8.127, 'epoch': 1.0}\n","{'eval_mnli_loss': 0.7123503088951111, 'eval_mnli_accuracy': 0.484160191273162, 'eval_mnli_runtime': 85.9566, 'eval_mnli_samples_per_second': 77.853, 'eval_mnli_steps_per_second': 7.795, 'epoch': 1.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.894108772277832, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0006, 'eval_hans-lexical_overlap-entailment_runtime': 64.6999, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.28, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.728, 'epoch': 2.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.5275821089744568, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9994, 'eval_hans-lexical_overlap-contradiction_runtime': 64.6705, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.315, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.732, 'epoch': 2.0}\n","{'eval_mnli_loss': 0.7161809206008911, 'eval_mnli_accuracy': 0.4852062163777645, 'eval_mnli_runtime': 87.4281, 'eval_mnli_samples_per_second': 76.543, 'eval_mnli_steps_per_second': 7.663, 'epoch': 2.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.873755156993866, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0066, 'eval_hans-lexical_overlap-entailment_runtime': 64.666, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.32, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.732, 'epoch': 3.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.5413135886192322, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.992, 'eval_hans-lexical_overlap-contradiction_runtime': 64.6678, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.318, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.732, 'epoch': 3.0}\n","{'eval_mnli_loss': 0.7141695022583008, 'eval_mnli_accuracy': 0.4892408846383742, 'eval_mnli_runtime': 87.3364, 'eval_mnli_samples_per_second': 76.623, 'eval_mnli_steps_per_second': 7.671, 'epoch': 3.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.8509777188301086, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0424, 'eval_hans-lexical_overlap-entailment_runtime': 64.7378, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.235, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.723, 'epoch': 4.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.5583996176719666, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9554, 'eval_hans-lexical_overlap-contradiction_runtime': 64.6942, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.287, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.729, 'epoch': 4.0}\n","{'eval_mnli_loss': 0.7203361392021179, 'eval_mnli_accuracy': 0.49118350268977884, 'eval_mnli_runtime': 87.4756, 'eval_mnli_samples_per_second': 76.501, 'eval_mnli_steps_per_second': 7.659, 'epoch': 4.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.7947051525115967, 'eval_hans-lexical_overlap-entailment_accuracy': 0.2154, 'eval_hans-lexical_overlap-entailment_runtime': 64.7261, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.249, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.725, 'epoch': 5.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.607491135597229, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.798, 'eval_hans-lexical_overlap-contradiction_runtime': 64.7122, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.265, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.727, 'epoch': 5.0}\n","{'eval_mnli_loss': 0.7125466465950012, 'eval_mnli_accuracy': 0.5209205020920502, 'eval_mnli_runtime': 87.3677, 'eval_mnli_samples_per_second': 76.596, 'eval_mnli_steps_per_second': 7.669, 'epoch': 5.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.5128157138824463, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9084, 'eval_hans-lexical_overlap-entailment_runtime': 64.7144, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.263, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.726, 'epoch': 6.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.9321492910385132, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.1018, 'eval_hans-lexical_overlap-contradiction_runtime': 64.6633, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.324, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.732, 'epoch': 6.0}\n","{'eval_mnli_loss': 0.6665155291557312, 'eval_mnli_accuracy': 0.6017632994620442, 'eval_mnli_runtime': 87.4564, 'eval_mnli_samples_per_second': 76.518, 'eval_mnli_steps_per_second': 7.661, 'epoch': 6.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.6020804643630981, 'eval_hans-lexical_overlap-entailment_accuracy': 0.6936, 'eval_hans-lexical_overlap-entailment_runtime': 64.7517, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.218, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.722, 'epoch': 7.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.8936798572540283, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.3184, 'eval_hans-lexical_overlap-contradiction_runtime': 64.7423, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.229, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.723, 'epoch': 7.0}\n","{'eval_mnli_loss': 0.8419836163520813, 'eval_mnli_accuracy': 0.5617154811715481, 'eval_mnli_runtime': 87.5123, 'eval_mnli_samples_per_second': 76.469, 'eval_mnli_steps_per_second': 7.656, 'epoch': 7.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.09656842797994614, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9904, 'eval_hans-lexical_overlap-entailment_runtime': 64.8029, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.157, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.716, 'epoch': 8.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.8124167919158936, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0188, 'eval_hans-lexical_overlap-contradiction_runtime': 64.7464, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.224, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.722, 'epoch': 8.0}\n","{'eval_mnli_loss': 1.0467662811279297, 'eval_mnli_accuracy': 0.6367304243873282, 'eval_mnli_runtime': 87.5254, 'eval_mnli_samples_per_second': 76.458, 'eval_mnli_steps_per_second': 7.655, 'epoch': 8.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.028146915137767792, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9926, 'eval_hans-lexical_overlap-entailment_runtime': 64.689, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.293, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.729, 'epoch': 9.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 7.1442742347717285, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0104, 'eval_hans-lexical_overlap-contradiction_runtime': 64.6538, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.335, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.734, 'epoch': 9.0}\n","{'eval_mnli_loss': 2.5536186695098877, 'eval_mnli_accuracy': 0.6147638971906755, 'eval_mnli_runtime': 87.4199, 'eval_mnli_samples_per_second': 76.55, 'eval_mnli_steps_per_second': 7.664, 'epoch': 9.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.030792638659477234, 'eval_hans-lexical_overlap-entailment_accuracy': 0.995, 'eval_hans-lexical_overlap-entailment_runtime': 64.8378, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.116, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.712, 'epoch': 10.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 11.16549301147461, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0078, 'eval_hans-lexical_overlap-contradiction_runtime': 64.8251, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.131, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.713, 'epoch': 10.0}\n","{'eval_mnli_loss': 3.7334632873535156, 'eval_mnli_accuracy': 0.6373281530185296, 'eval_mnli_runtime': 87.3031, 'eval_mnli_samples_per_second': 76.652, 'eval_mnli_steps_per_second': 7.674, 'epoch': 10.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.05949494615197182, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9938, 'eval_hans-lexical_overlap-entailment_runtime': 64.698, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.282, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.728, 'epoch': 11.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 14.541169166564941, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0096, 'eval_hans-lexical_overlap-contradiction_runtime': 64.7434, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.228, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.723, 'epoch': 11.0}\n","{'eval_mnli_loss': 5.735307693481445, 'eval_mnli_accuracy': 0.5975791990436342, 'eval_mnli_runtime': 87.3936, 'eval_mnli_samples_per_second': 76.573, 'eval_mnli_steps_per_second': 7.666, 'epoch': 11.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0010462935315445065, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.7316, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.242, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.724, 'epoch': 12.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 16.70107650756836, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.6856, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.297, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.73, 'epoch': 12.0}\n","{'eval_mnli_loss': 5.713710784912109, 'eval_mnli_accuracy': 0.6376270173341303, 'eval_mnli_runtime': 87.3272, 'eval_mnli_samples_per_second': 76.631, 'eval_mnli_steps_per_second': 7.672, 'epoch': 12.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0016343053430318832, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.7516, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.218, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.722, 'epoch': 13.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 17.186128616333008, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.7056, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.273, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.727, 'epoch': 13.0}\n","{'eval_mnli_loss': 5.951521873474121, 'eval_mnli_accuracy': 0.6352361028093245, 'eval_mnli_runtime': 87.4339, 'eval_mnli_samples_per_second': 76.538, 'eval_mnli_steps_per_second': 7.663, 'epoch': 13.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0012825200101360679, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.8176, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.14, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.714, 'epoch': 14.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 17.467103958129883, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.7551, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.214, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.721, 'epoch': 14.0}\n","{'eval_mnli_loss': 5.997452735900879, 'eval_mnli_accuracy': 0.6353855349671249, 'eval_mnli_runtime': 87.4455, 'eval_mnli_samples_per_second': 76.528, 'eval_mnli_steps_per_second': 7.662, 'epoch': 14.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0004867168318014592, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.8768, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.069, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.707, 'epoch': 15.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 17.62586212158203, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.7074, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.271, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.727, 'epoch': 15.0}\n","{'eval_mnli_loss': 5.996635437011719, 'eval_mnli_accuracy': 0.635833831440526, 'eval_mnli_runtime': 87.4908, 'eval_mnli_samples_per_second': 76.488, 'eval_mnli_steps_per_second': 7.658, 'epoch': 15.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0007063659722916782, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.8454, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.106, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.711, 'epoch': 16.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 17.713924407958984, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.7784, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.186, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.719, 'epoch': 16.0}\n","{'eval_mnli_loss': 6.074509620666504, 'eval_mnli_accuracy': 0.633741781231321, 'eval_mnli_runtime': 87.4886, 'eval_mnli_samples_per_second': 76.49, 'eval_mnli_steps_per_second': 7.658, 'epoch': 16.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0007199134561233222, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.7803, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.184, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.718, 'epoch': 17.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 17.752944946289062, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.6414, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.35, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.735, 'epoch': 17.0}\n","{'eval_mnli_loss': 6.121304988861084, 'eval_mnli_accuracy': 0.6326957561267185, 'eval_mnli_runtime': 87.4557, 'eval_mnli_samples_per_second': 76.519, 'eval_mnli_steps_per_second': 7.661, 'epoch': 17.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0012673892779275775, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.7303, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.244, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.724, 'epoch': 18.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 17.76845359802246, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.8255, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.13, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.713, 'epoch': 18.0}\n","{'eval_mnli_loss': 6.18501091003418, 'eval_mnli_accuracy': 0.6288105200239091, 'eval_mnli_runtime': 87.5882, 'eval_mnli_samples_per_second': 76.403, 'eval_mnli_steps_per_second': 7.649, 'epoch': 18.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0011187652125954628, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.8187, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.138, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.714, 'epoch': 19.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 17.78744888305664, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.8781, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.068, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.707, 'epoch': 19.0}\n","{'eval_mnli_loss': 6.184534549713135, 'eval_mnli_accuracy': 0.6294082486551106, 'eval_mnli_runtime': 87.3355, 'eval_mnli_samples_per_second': 76.624, 'eval_mnli_steps_per_second': 7.672, 'epoch': 19.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.00105107796844095, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_runtime': 64.6462, 'eval_hans-lexical_overlap-entailment_samples_per_second': 77.344, 'eval_hans-lexical_overlap-entailment_steps_per_second': 7.734, 'epoch': 20.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 17.795970916748047, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 64.6306, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 77.363, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 7.736, 'epoch': 20.0}\n","{'eval_mnli_loss': 6.181707382202148, 'eval_mnli_accuracy': 0.6289599521817095, 'eval_mnli_runtime': 87.1114, 'eval_mnli_samples_per_second': 76.821, 'eval_mnli_steps_per_second': 7.691, 'epoch': 20.0}\n","{'train_runtime': 4458.7939, 'train_samples_per_second': 0.574, 'train_steps_per_second': 0.144, 'train_loss': 0.20253982543945312, 'epoch': 20.0}\n","***** train metrics *****\n","  epoch                    =       20.0\n","  train_loss               =     0.2025\n","  train_runtime            = 1:14:18.79\n","  train_samples            =        128\n","  train_samples_per_second =      0.574\n","  train_steps_per_second   =      0.144\n"]}],"source":["# FT experiment (original)\n","# args: task_name, max_train_samples, epochs, warmup_ratio, bsz, num_gpus, learning_rate, model_name_or_path, port\n","#bash $PROJECT_DIR/scripts/pattern_verbalizer_ft/mnli/run.sh mnli 128 40 0.5 4 8 1e-5 facebook/opt-13b 60000\n","\n","import os\n","os.environ['PROJECT_DIR']=\"/content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft\"\n","#os.environ['WANDB_DISABLED']='False'\n","\n","!python /content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft/ft.py \\\n","            --wandb_project_name llmft-experiments \\\n","            --wandb_group_name vanilla-ft \\\n","            --model_name_or_path facebook/opt-125m \\\n","            --cache_dir \"./hf_model\" \\\n","            --task_name mnli \\\n","            --pattern \"{text1} {text2} ?\" \\\n","            --dataset_cache_dir \"./hf_dataset\" \\\n","            --max_seq_length 256 \\\n","            --output_dir \"./output\" \\\n","            --overwrite_output_dir \\\n","            --do_train \\\n","            --max_train_samples 16 \\\n","            --per_device_train_batch_size 4 \\\n","            --gradient_accumulation_steps 1 \\\n","            --num_train_epochs 40 \\\n","            --warmup_ratio 0.5 \\\n","            --logging_first_step false \\\n","            --logging_steps -1 \\\n","            --learning_rate 1e-5 \\\n","            --weight_decay 0.0 \\\n","            --do_eval \\\n","            --evaluation_strategy epoch \\\n","            --per_device_eval_batch_size 10 \\\n","            --eval_on_hans \\\n","            --save_strategy no \\\n","            --fp16 \\\n","            --seed 0 \\\n","            --data_seed 0 \\\n","            --report_to \"none\" \\\n","            2> /content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft/logs/console.err\n"]},{"cell_type":"code","source":[],"metadata":{"id":"o1rOo3iqilU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FT+ experiment (context distillation with language model head)\n","# args: task_name, max_train_samples, epochs, warmup_ratio, bsz, num_gpus, learning_rate, model_name_or_path, port\n","#bash $PROJECT_DIR/scripts/pattern_verbalizer_ft/mnli/run.sh mnli 128 40 0.5 4 8 1e-5 facebook/opt-13b 60000\n","\n","import os\n","os.environ['PROJECT_DIR']=\"/content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft\"\n","#os.environ['WANDB_DISABLED']='False'\n","\n","!python /content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft/ft.py \\\n","            --wandb_project_name llmft-experiments \\\n","            --wandb_group_name vanilla-ft \\\n","            --model_name_or_path facebook/opt-125m \\\n","            --cache_dir \"./hf_model\" \\\n","            --task_name mnli \\\n","            --pattern \"{text1} {text2} ?\" \\\n","            --target_tokens \"Ġ1,Ġ0\" \\\n","            --dataset_cache_dir \"./hf_dataset\" \\\n","            --max_seq_length 256 \\\n","            --output_dir \"./output\" \\\n","            --overwrite_output_dir \\\n","            --do_train \\\n","            --max_train_samples 16 \\\n","            --per_device_train_batch_size 16 \\\n","            --gradient_accumulation_steps 1 \\\n","            --num_train_epochs 50 \\\n","            --warmup_ratio 0.5 \\\n","            --logging_first_step false \\\n","            --logging_steps -1 \\\n","            --learning_rate 1e-4 \\\n","            --weight_decay 0.0 \\\n","            --do_eval \\\n","            --evaluation_strategy epoch \\\n","            --per_device_eval_batch_size 32 \\\n","            --eval_on_hans \\\n","            --save_strategy no \\\n","            --fp16 \\\n","            --seed 0 \\\n","            --data_seed 0 \\\n","            --report_to \"none\" \\\n","            2> /content/drive/MyDrive/Colab-Notebooks/cs7643-prj/llmft/logs/console.err\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V5ioYMyi3Q11","outputId":"5aea77a3-8b69-4cdb-8109-f3f2b839be1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-04-25 01:32:21,802] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n","\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n","\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n","\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n","\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n","\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n","\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n","Sample 12 of the training set: {'premise': 'and it is really really good about the um Saudis and just tracking their families and the Arabian culture', 'hypothesis': 'It often loses track of certain Saudis.', 'label': 321, 'idx': 275133, 'input_ids': [2, 463, 24, 16, 269, 269, 205, 59, 5, 7252, 20313, 8, 95, 6779, 49, 1232, 8, 5, 22656, 2040, 85, 747, 13585, 1349, 9, 1402, 20313, 4, 17487, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'soft_prompt_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_tokens': ['</s>', 'and', 'Ġit', 'Ġis', 'Ġreally', 'Ġreally', 'Ġgood', 'Ġabout', 'Ġthe', 'Ġum', 'ĠSaudis', 'Ġand', 'Ġjust', 'Ġtracking', 'Ġtheir', 'Ġfamilies', 'Ġand', 'Ġthe', 'ĠArabian', 'Ġculture', 'ĠIt', 'Ġoften', 'Ġloses', 'Ġtrack', 'Ġof', 'Ġcertain', 'ĠSaudis', '.', 'Ġ?', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'input_text': '</s>and it is really really good about the um Saudis and just tracking their families and the Arabian culture It often loses track of certain Saudis.?<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'label_text': 'contradiction'}.\n","Trainable parameters: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'p0.model.decoder.embed_tokens.weight', 'p0.model.decoder.embed_positions.weight', 'p0.model.decoder.final_layer_norm.weight', 'p0.model.decoder.final_layer_norm.bias', 'p0.model.decoder.layers.0.self_attn.k_proj.weight', 'p0.model.decoder.layers.0.self_attn.k_proj.bias', 'p0.model.decoder.layers.0.self_attn.v_proj.weight', 'p0.model.decoder.layers.0.self_attn.v_proj.bias', 'p0.model.decoder.layers.0.self_attn.q_proj.weight', 'p0.model.decoder.layers.0.self_attn.q_proj.bias', 'p0.model.decoder.layers.0.self_attn.out_proj.weight', 'p0.model.decoder.layers.0.self_attn.out_proj.bias', 'p0.model.decoder.layers.0.self_attn_layer_norm.weight', 'p0.model.decoder.layers.0.self_attn_layer_norm.bias', 'p0.model.decoder.layers.0.fc1.weight', 'p0.model.decoder.layers.0.fc1.bias', 'p0.model.decoder.layers.0.fc2.weight', 'p0.model.decoder.layers.0.fc2.bias', 'p0.model.decoder.layers.0.final_layer_norm.weight', 'p0.model.decoder.layers.0.final_layer_norm.bias', 'p0.model.decoder.layers.1.self_attn.k_proj.weight', 'p0.model.decoder.layers.1.self_attn.k_proj.bias', 'p0.model.decoder.layers.1.self_attn.v_proj.weight', 'p0.model.decoder.layers.1.self_attn.v_proj.bias', 'p0.model.decoder.layers.1.self_attn.q_proj.weight', 'p0.model.decoder.layers.1.self_attn.q_proj.bias', 'p0.model.decoder.layers.1.self_attn.out_proj.weight', 'p0.model.decoder.layers.1.self_attn.out_proj.bias', 'p0.model.decoder.layers.1.self_attn_layer_norm.weight', 'p0.model.decoder.layers.1.self_attn_layer_norm.bias', 'p0.model.decoder.layers.1.fc1.weight', 'p0.model.decoder.layers.1.fc1.bias', 'p0.model.decoder.layers.1.fc2.weight', 'p0.model.decoder.layers.1.fc2.bias', 'p0.model.decoder.layers.1.final_layer_norm.weight', 'p0.model.decoder.layers.1.final_layer_norm.bias', 'p0.model.decoder.layers.2.self_attn.k_proj.weight', 'p0.model.decoder.layers.2.self_attn.k_proj.bias', 'p0.model.decoder.layers.2.self_attn.v_proj.weight', 'p0.model.decoder.layers.2.self_attn.v_proj.bias', 'p0.model.decoder.layers.2.self_attn.q_proj.weight', 'p0.model.decoder.layers.2.self_attn.q_proj.bias', 'p0.model.decoder.layers.2.self_attn.out_proj.weight', 'p0.model.decoder.layers.2.self_attn.out_proj.bias', 'p0.model.decoder.layers.2.self_attn_layer_norm.weight', 'p0.model.decoder.layers.2.self_attn_layer_norm.bias', 'p0.model.decoder.layers.2.fc1.weight', 'p0.model.decoder.layers.2.fc1.bias', 'p0.model.decoder.layers.2.fc2.weight', 'p0.model.decoder.layers.2.fc2.bias', 'p0.model.decoder.layers.2.final_layer_norm.weight', 'p0.model.decoder.layers.2.final_layer_norm.bias', 'p0.model.decoder.layers.3.self_attn.k_proj.weight', 'p0.model.decoder.layers.3.self_attn.k_proj.bias', 'p0.model.decoder.layers.3.self_attn.v_proj.weight', 'p0.model.decoder.layers.3.self_attn.v_proj.bias', 'p0.model.decoder.layers.3.self_attn.q_proj.weight', 'p0.model.decoder.layers.3.self_attn.q_proj.bias', 'p0.model.decoder.layers.3.self_attn.out_proj.weight', 'p0.model.decoder.layers.3.self_attn.out_proj.bias', 'p0.model.decoder.layers.3.self_attn_layer_norm.weight', 'p0.model.decoder.layers.3.self_attn_layer_norm.bias', 'p0.model.decoder.layers.3.fc1.weight', 'p0.model.decoder.layers.3.fc1.bias', 'p0.model.decoder.layers.3.fc2.weight', 'p0.model.decoder.layers.3.fc2.bias', 'p0.model.decoder.layers.3.final_layer_norm.weight', 'p0.model.decoder.layers.3.final_layer_norm.bias', 'p0.model.decoder.layers.4.self_attn.k_proj.weight', 'p0.model.decoder.layers.4.self_attn.k_proj.bias', 'p0.model.decoder.layers.4.self_attn.v_proj.weight', 'p0.model.decoder.layers.4.self_attn.v_proj.bias', 'p0.model.decoder.layers.4.self_attn.q_proj.weight', 'p0.model.decoder.layers.4.self_attn.q_proj.bias', 'p0.model.decoder.layers.4.self_attn.out_proj.weight', 'p0.model.decoder.layers.4.self_attn.out_proj.bias', 'p0.model.decoder.layers.4.self_attn_layer_norm.weight', 'p0.model.decoder.layers.4.self_attn_layer_norm.bias', 'p0.model.decoder.layers.4.fc1.weight', 'p0.model.decoder.layers.4.fc1.bias', 'p0.model.decoder.layers.4.fc2.weight', 'p0.model.decoder.layers.4.fc2.bias', 'p0.model.decoder.layers.4.final_layer_norm.weight', 'p0.model.decoder.layers.4.final_layer_norm.bias', 'p0.model.decoder.layers.5.self_attn.k_proj.weight', 'p0.model.decoder.layers.5.self_attn.k_proj.bias', 'p0.model.decoder.layers.5.self_attn.v_proj.weight', 'p0.model.decoder.layers.5.self_attn.v_proj.bias', 'p0.model.decoder.layers.5.self_attn.q_proj.weight', 'p0.model.decoder.layers.5.self_attn.q_proj.bias', 'p0.model.decoder.layers.5.self_attn.out_proj.weight', 'p0.model.decoder.layers.5.self_attn.out_proj.bias', 'p0.model.decoder.layers.5.self_attn_layer_norm.weight', 'p0.model.decoder.layers.5.self_attn_layer_norm.bias', 'p0.model.decoder.layers.5.fc1.weight', 'p0.model.decoder.layers.5.fc1.bias', 'p0.model.decoder.layers.5.fc2.weight', 'p0.model.decoder.layers.5.fc2.bias', 'p0.model.decoder.layers.5.final_layer_norm.weight', 'p0.model.decoder.layers.5.final_layer_norm.bias', 'p0.model.decoder.layers.6.self_attn.k_proj.weight', 'p0.model.decoder.layers.6.self_attn.k_proj.bias', 'p0.model.decoder.layers.6.self_attn.v_proj.weight', 'p0.model.decoder.layers.6.self_attn.v_proj.bias', 'p0.model.decoder.layers.6.self_attn.q_proj.weight', 'p0.model.decoder.layers.6.self_attn.q_proj.bias', 'p0.model.decoder.layers.6.self_attn.out_proj.weight', 'p0.model.decoder.layers.6.self_attn.out_proj.bias', 'p0.model.decoder.layers.6.self_attn_layer_norm.weight', 'p0.model.decoder.layers.6.self_attn_layer_norm.bias', 'p0.model.decoder.layers.6.fc1.weight', 'p0.model.decoder.layers.6.fc1.bias', 'p0.model.decoder.layers.6.fc2.weight', 'p0.model.decoder.layers.6.fc2.bias', 'p0.model.decoder.layers.6.final_layer_norm.weight', 'p0.model.decoder.layers.6.final_layer_norm.bias', 'p0.model.decoder.layers.7.self_attn.k_proj.weight', 'p0.model.decoder.layers.7.self_attn.k_proj.bias', 'p0.model.decoder.layers.7.self_attn.v_proj.weight', 'p0.model.decoder.layers.7.self_attn.v_proj.bias', 'p0.model.decoder.layers.7.self_attn.q_proj.weight', 'p0.model.decoder.layers.7.self_attn.q_proj.bias', 'p0.model.decoder.layers.7.self_attn.out_proj.weight', 'p0.model.decoder.layers.7.self_attn.out_proj.bias', 'p0.model.decoder.layers.7.self_attn_layer_norm.weight', 'p0.model.decoder.layers.7.self_attn_layer_norm.bias', 'p0.model.decoder.layers.7.fc1.weight', 'p0.model.decoder.layers.7.fc1.bias', 'p0.model.decoder.layers.7.fc2.weight', 'p0.model.decoder.layers.7.fc2.bias', 'p0.model.decoder.layers.7.final_layer_norm.weight', 'p0.model.decoder.layers.7.final_layer_norm.bias', 'p0.model.decoder.layers.8.self_attn.k_proj.weight', 'p0.model.decoder.layers.8.self_attn.k_proj.bias', 'p0.model.decoder.layers.8.self_attn.v_proj.weight', 'p0.model.decoder.layers.8.self_attn.v_proj.bias', 'p0.model.decoder.layers.8.self_attn.q_proj.weight', 'p0.model.decoder.layers.8.self_attn.q_proj.bias', 'p0.model.decoder.layers.8.self_attn.out_proj.weight', 'p0.model.decoder.layers.8.self_attn.out_proj.bias', 'p0.model.decoder.layers.8.self_attn_layer_norm.weight', 'p0.model.decoder.layers.8.self_attn_layer_norm.bias', 'p0.model.decoder.layers.8.fc1.weight', 'p0.model.decoder.layers.8.fc1.bias', 'p0.model.decoder.layers.8.fc2.weight', 'p0.model.decoder.layers.8.fc2.bias', 'p0.model.decoder.layers.8.final_layer_norm.weight', 'p0.model.decoder.layers.8.final_layer_norm.bias', 'p0.model.decoder.layers.9.self_attn.k_proj.weight', 'p0.model.decoder.layers.9.self_attn.k_proj.bias', 'p0.model.decoder.layers.9.self_attn.v_proj.weight', 'p0.model.decoder.layers.9.self_attn.v_proj.bias', 'p0.model.decoder.layers.9.self_attn.q_proj.weight', 'p0.model.decoder.layers.9.self_attn.q_proj.bias', 'p0.model.decoder.layers.9.self_attn.out_proj.weight', 'p0.model.decoder.layers.9.self_attn.out_proj.bias', 'p0.model.decoder.layers.9.self_attn_layer_norm.weight', 'p0.model.decoder.layers.9.self_attn_layer_norm.bias', 'p0.model.decoder.layers.9.fc1.weight', 'p0.model.decoder.layers.9.fc1.bias', 'p0.model.decoder.layers.9.fc2.weight', 'p0.model.decoder.layers.9.fc2.bias', 'p0.model.decoder.layers.9.final_layer_norm.weight', 'p0.model.decoder.layers.9.final_layer_norm.bias', 'p0.model.decoder.layers.10.self_attn.k_proj.weight', 'p0.model.decoder.layers.10.self_attn.k_proj.bias', 'p0.model.decoder.layers.10.self_attn.v_proj.weight', 'p0.model.decoder.layers.10.self_attn.v_proj.bias', 'p0.model.decoder.layers.10.self_attn.q_proj.weight', 'p0.model.decoder.layers.10.self_attn.q_proj.bias', 'p0.model.decoder.layers.10.self_attn.out_proj.weight', 'p0.model.decoder.layers.10.self_attn.out_proj.bias', 'p0.model.decoder.layers.10.self_attn_layer_norm.weight', 'p0.model.decoder.layers.10.self_attn_layer_norm.bias', 'p0.model.decoder.layers.10.fc1.weight', 'p0.model.decoder.layers.10.fc1.bias', 'p0.model.decoder.layers.10.fc2.weight', 'p0.model.decoder.layers.10.fc2.bias', 'p0.model.decoder.layers.10.final_layer_norm.weight', 'p0.model.decoder.layers.10.final_layer_norm.bias', 'p0.model.decoder.layers.11.self_attn.k_proj.weight', 'p0.model.decoder.layers.11.self_attn.k_proj.bias', 'p0.model.decoder.layers.11.self_attn.v_proj.weight', 'p0.model.decoder.layers.11.self_attn.v_proj.bias', 'p0.model.decoder.layers.11.self_attn.q_proj.weight', 'p0.model.decoder.layers.11.self_attn.q_proj.bias', 'p0.model.decoder.layers.11.self_attn.out_proj.weight', 'p0.model.decoder.layers.11.self_attn.out_proj.bias', 'p0.model.decoder.layers.11.self_attn_layer_norm.weight', 'p0.model.decoder.layers.11.self_attn_layer_norm.bias', 'p0.model.decoder.layers.11.fc1.weight', 'p0.model.decoder.layers.11.fc1.bias', 'p0.model.decoder.layers.11.fc2.weight', 'p0.model.decoder.layers.11.fc2.bias', 'p0.model.decoder.layers.11.final_layer_norm.weight', 'p0.model.decoder.layers.11.final_layer_norm.bias', 'p0.lm_head.weight']\n","override self.deepspeed to False\n","{'eval_hans-lexical_overlap-entailment_loss': 8.40011215209961, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-entailment_runtime': 86.7662, 'eval_hans-lexical_overlap-entailment_samples_per_second': 57.626, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.809, 'epoch': 1.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 9.86875057220459, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-contradiction_runtime': 90.1957, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 55.435, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.741, 'epoch': 1.0}\n","{'eval_mnli_loss': 9.576363563537598, 'eval_mnli_accuracy': 0.0, 'eval_mnli_frac_non_target_tokens': 1.0, 'eval_mnli_runtime': 122.0965, 'eval_mnli_samples_per_second': 54.809, 'eval_mnli_steps_per_second': 1.72, 'epoch': 1.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 7.98378849029541, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-entailment_runtime': 91.7688, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.485, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.711, 'epoch': 2.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 9.310144424438477, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-contradiction_runtime': 91.8509, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.436, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.709, 'epoch': 2.0}\n","{'eval_mnli_loss': 8.996858596801758, 'eval_mnli_accuracy': 0.0, 'eval_mnli_frac_non_target_tokens': 1.0, 'eval_mnli_runtime': 124.7281, 'eval_mnli_samples_per_second': 53.653, 'eval_mnli_steps_per_second': 1.684, 'epoch': 2.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 7.109692096710205, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.0503, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.318, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.706, 'epoch': 3.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 8.148530006408691, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-contradiction_runtime': 91.9744, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.363, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.707, 'epoch': 3.0}\n","{'eval_mnli_loss': 7.785257339477539, 'eval_mnli_accuracy': 0.0, 'eval_mnli_frac_non_target_tokens': 1.0, 'eval_mnli_runtime': 124.7398, 'eval_mnli_samples_per_second': 53.648, 'eval_mnli_steps_per_second': 1.684, 'epoch': 3.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 5.733150959014893, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.1175, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.279, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.704, 'epoch': 4.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 6.266875743865967, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0197, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.336, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.706, 'epoch': 4.0}\n","{'eval_mnli_loss': 5.827611446380615, 'eval_mnli_accuracy': 0.00014943215780035862, 'eval_mnli_frac_non_target_tokens': 0.9994022713687986, 'eval_mnli_runtime': 124.6708, 'eval_mnli_samples_per_second': 53.677, 'eval_mnli_steps_per_second': 1.684, 'epoch': 4.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 4.1217570304870605, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.212, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.223, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.703, 'epoch': 5.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.984360933303833, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.9998, 'eval_hans-lexical_overlap-contradiction_runtime': 92.2063, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.226, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.703, 'epoch': 5.0}\n","{'eval_mnli_loss': 3.7195076942443848, 'eval_mnli_accuracy': 0.06186491332934847, 'eval_mnli_frac_non_target_tokens': 0.8469814704124328, 'eval_mnli_runtime': 124.5777, 'eval_mnli_samples_per_second': 53.717, 'eval_mnli_steps_per_second': 1.686, 'epoch': 5.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 2.621020793914795, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.1312, 'eval_hans-lexical_overlap-entailment_runtime': 92.184, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.239, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.703, 'epoch': 6.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.8138121366500854, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.8582, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.1418, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1626, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.252, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.704, 'epoch': 6.0}\n","{'eval_mnli_loss': 2.145681381225586, 'eval_mnli_accuracy': 0.43544530783024504, 'eval_mnli_frac_non_target_tokens': 0.09847579199043634, 'eval_mnli_runtime': 124.7194, 'eval_mnli_samples_per_second': 53.656, 'eval_mnli_steps_per_second': 1.684, 'epoch': 6.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 2.052823543548584, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.3289, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.154, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.7, 'epoch': 7.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.5313386917114258, 'eval_hans-lexical_overlap-contradiction_accuracy': 1.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.2453, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.203, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.702, 'epoch': 7.0}\n","{'eval_mnli_loss': 1.494421124458313, 'eval_mnli_accuracy': 0.4739988045427376, 'eval_mnli_frac_non_target_tokens': 0.012851165570830842, 'eval_mnli_runtime': 124.5997, 'eval_mnli_samples_per_second': 53.708, 'eval_mnli_steps_per_second': 1.685, 'epoch': 7.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.8652607202529907, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 91.9794, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.36, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.707, 'epoch': 8.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.2923048436641693, 'eval_hans-lexical_overlap-contradiction_accuracy': 1.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.213, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.222, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.703, 'epoch': 8.0}\n","{'eval_mnli_loss': 1.3116265535354614, 'eval_mnli_accuracy': 0.47982665869695157, 'eval_mnli_frac_non_target_tokens': 0.0005977286312014345, 'eval_mnli_runtime': 124.5456, 'eval_mnli_samples_per_second': 53.731, 'eval_mnli_steps_per_second': 1.686, 'epoch': 8.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.3058369159698486, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.0322, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.329, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.706, 'epoch': 9.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.3935530185699463, 'eval_hans-lexical_overlap-contradiction_accuracy': 1.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.2736, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.187, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.701, 'epoch': 9.0}\n","{'eval_mnli_loss': 0.9882767796516418, 'eval_mnli_accuracy': 0.4802749551703527, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.278, 'eval_mnli_samples_per_second': 53.847, 'eval_mnli_steps_per_second': 1.69, 'epoch': 9.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.43956610560417175, 'eval_hans-lexical_overlap-entailment_accuracy': 0.986, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.0793, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.301, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.705, 'epoch': 10.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.1361697912216187, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0188, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1274, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.273, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.704, 'epoch': 10.0}\n","{'eval_mnli_loss': 0.7197386622428894, 'eval_mnli_accuracy': 0.5657501494321578, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.5574, 'eval_mnli_samples_per_second': 53.726, 'eval_mnli_steps_per_second': 1.686, 'epoch': 10.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.53426593542099, 'eval_hans-lexical_overlap-entailment_accuracy': 0.8556, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.3786, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.125, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.7, 'epoch': 11.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.9795607328414917, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.1254, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1786, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.243, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.703, 'epoch': 11.0}\n","{'eval_mnli_loss': 0.7233008146286011, 'eval_mnli_accuracy': 0.5527495517035266, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.9816, 'eval_mnli_samples_per_second': 53.544, 'eval_mnli_steps_per_second': 1.68, 'epoch': 11.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.4858394861221313, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0114, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.3178, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.161, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.701, 'epoch': 12.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.32263967394828796, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9782, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.2589, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.195, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.702, 'epoch': 12.0}\n","{'eval_mnli_loss': 1.1477530002593994, 'eval_mnli_accuracy': 0.4887925881649731, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.6916, 'eval_mnli_samples_per_second': 53.668, 'eval_mnli_steps_per_second': 1.684, 'epoch': 12.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.876326560974121, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0044, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.183, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.24, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.703, 'epoch': 13.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.22709526121616364, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.992, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.3129, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.164, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.701, 'epoch': 13.0}\n","{'eval_mnli_loss': 1.4672433137893677, 'eval_mnli_accuracy': 0.4849073520621638, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.7404, 'eval_mnli_samples_per_second': 53.647, 'eval_mnli_steps_per_second': 1.683, 'epoch': 13.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.2615259885787964, 'eval_hans-lexical_overlap-entailment_accuracy': 0.1604, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.0579, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.314, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.705, 'epoch': 14.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.4806351661682129, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.7924, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1999, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.23, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.703, 'epoch': 14.0}\n","{'eval_mnli_loss': 1.2916499376296997, 'eval_mnli_accuracy': 0.5011954572624029, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.4207, 'eval_mnli_samples_per_second': 53.785, 'eval_mnli_steps_per_second': 1.688, 'epoch': 14.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.4793790578842163, 'eval_hans-lexical_overlap-entailment_accuracy': 0.1686, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.0786, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.301, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.705, 'epoch': 15.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.4627358913421631, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.782, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1579, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.255, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.704, 'epoch': 15.0}\n","{'eval_mnli_loss': 1.6303374767303467, 'eval_mnli_accuracy': 0.49940227136879856, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.633, 'eval_mnli_samples_per_second': 53.694, 'eval_mnli_steps_per_second': 1.685, 'epoch': 15.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 2.3848443031311035, 'eval_hans-lexical_overlap-entailment_accuracy': 0.062, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.0955, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.291, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.705, 'epoch': 16.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.25967657566070557, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9036, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.031, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.33, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.706, 'epoch': 16.0}\n","{'eval_mnli_loss': 2.3880341053009033, 'eval_mnli_accuracy': 0.494172145845786, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.5395, 'eval_mnli_samples_per_second': 53.734, 'eval_mnli_steps_per_second': 1.686, 'epoch': 16.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 4.399971961975098, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0056, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.001, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.347, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.707, 'epoch': 17.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.06301162391901016, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9904, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0311, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.329, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.706, 'epoch': 17.0}\n","{'eval_mnli_loss': 3.6369895935058594, 'eval_mnli_accuracy': 0.48565451285116557, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.5353, 'eval_mnli_samples_per_second': 53.736, 'eval_mnli_steps_per_second': 1.686, 'epoch': 17.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 5.027885437011719, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0136, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.119, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.278, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.704, 'epoch': 18.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.06919288635253906, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9814, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1447, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.262, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.704, 'epoch': 18.0}\n","{'eval_mnli_loss': 4.128033638000488, 'eval_mnli_accuracy': 0.4917812313209803, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.7686, 'eval_mnli_samples_per_second': 53.635, 'eval_mnli_steps_per_second': 1.683, 'epoch': 18.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 4.7412028312683105, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0426, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 91.9675, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.367, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.707, 'epoch': 19.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.14688417315483093, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.94, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0916, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.294, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.705, 'epoch': 19.0}\n","{'eval_mnli_loss': 4.214592933654785, 'eval_mnli_accuracy': 0.49611476389719067, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.5991, 'eval_mnli_samples_per_second': 53.708, 'eval_mnli_steps_per_second': 1.685, 'epoch': 19.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 6.115717887878418, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0252, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.2389, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.207, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.702, 'epoch': 20.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.098166823387146, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9606, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1102, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.283, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.704, 'epoch': 20.0}\n","{'eval_mnli_loss': 5.169158935546875, 'eval_mnli_accuracy': 0.4931261207411835, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.8599, 'eval_mnli_samples_per_second': 53.596, 'eval_mnli_steps_per_second': 1.682, 'epoch': 20.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 7.155056476593018, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0238, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.1775, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.243, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.703, 'epoch': 21.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.0963006466627121, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.961, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0359, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.327, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.706, 'epoch': 21.0}\n","{'eval_mnli_loss': 5.905972003936768, 'eval_mnli_accuracy': 0.4919306634787806, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.6019, 'eval_mnli_samples_per_second': 53.707, 'eval_mnli_steps_per_second': 1.685, 'epoch': 21.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 8.793815612792969, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0148, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.0675, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.308, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.705, 'epoch': 22.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.05870635807514191, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9768, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.09, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.295, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.705, 'epoch': 22.0}\n","{'eval_mnli_loss': 6.767853736877441, 'eval_mnli_accuracy': 0.4887925881649731, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.5646, 'eval_mnli_samples_per_second': 53.723, 'eval_mnli_steps_per_second': 1.686, 'epoch': 22.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 10.503881454467773, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0088, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 91.9983, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.349, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.707, 'epoch': 23.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.033334724605083466, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9864, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 91.9129, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.399, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.708, 'epoch': 23.0}\n","{'eval_mnli_loss': 7.582984924316406, 'eval_mnli_accuracy': 0.48640167364016734, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.6935, 'eval_mnli_samples_per_second': 53.668, 'eval_mnli_steps_per_second': 1.684, 'epoch': 23.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 11.908713340759277, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0054, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.1399, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.265, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.704, 'epoch': 24.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.021074999123811722, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9924, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0003, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.348, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.707, 'epoch': 24.0}\n","{'eval_mnli_loss': 8.18591022491455, 'eval_mnli_accuracy': 0.4849073520621638, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.62, 'eval_mnli_samples_per_second': 53.699, 'eval_mnli_steps_per_second': 1.685, 'epoch': 24.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 10.421285629272461, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0206, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.0815, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.3, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.705, 'epoch': 25.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.08722405135631561, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9666, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0851, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.298, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.705, 'epoch': 25.0}\n","{'eval_mnli_loss': 7.682288646697998, 'eval_mnli_accuracy': 0.49013747758517634, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.6199, 'eval_mnli_samples_per_second': 53.699, 'eval_mnli_steps_per_second': 1.685, 'epoch': 25.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 8.15563678741455, 'eval_hans-lexical_overlap-entailment_accuracy': 0.07, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.1129, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.281, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.704, 'epoch': 26.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.3136690557003021, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.8984, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 91.7788, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.479, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.711, 'epoch': 26.0}\n","{'eval_mnli_loss': 6.824244499206543, 'eval_mnli_accuracy': 0.4934249850567842, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.3158, 'eval_mnli_samples_per_second': 53.831, 'eval_mnli_steps_per_second': 1.689, 'epoch': 26.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 6.461817741394043, 'eval_hans-lexical_overlap-entailment_accuracy': 0.1228, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 91.8315, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.448, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.71, 'epoch': 27.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.6265707015991211, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.8178, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 91.8919, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.412, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.709, 'epoch': 27.0}\n","{'eval_mnli_loss': 6.098943710327148, 'eval_mnli_accuracy': 0.4974596533173939, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.7561, 'eval_mnli_samples_per_second': 53.641, 'eval_mnli_steps_per_second': 1.683, 'epoch': 27.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 5.735737323760986, 'eval_hans-lexical_overlap-entailment_accuracy': 0.1528, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.2574, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.196, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.702, 'epoch': 28.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.8010339736938477, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.7748, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1834, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.24, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.703, 'epoch': 28.0}\n","{'eval_mnli_loss': 5.7231831550598145, 'eval_mnli_accuracy': 0.4977585176329946, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.2252, 'eval_mnli_samples_per_second': 53.87, 'eval_mnli_steps_per_second': 1.69, 'epoch': 28.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 7.21458101272583, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0956, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 91.9048, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.404, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.708, 'epoch': 29.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.46025633811950684, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.8562, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0474, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.32, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.706, 'epoch': 29.0}\n","{'eval_mnli_loss': 6.216178894042969, 'eval_mnli_accuracy': 0.4949193066347878, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.2872, 'eval_mnli_samples_per_second': 53.843, 'eval_mnli_steps_per_second': 1.69, 'epoch': 29.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 9.586128234863281, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0342, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 91.8779, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.42, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.709, 'epoch': 30.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.1586349904537201, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9404, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.2779, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.184, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.701, 'epoch': 30.0}\n","{'eval_mnli_loss': 7.028809070587158, 'eval_mnli_accuracy': 0.49013747758517634, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.2012, 'eval_mnli_samples_per_second': 53.88, 'eval_mnli_steps_per_second': 1.691, 'epoch': 30.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 11.503235816955566, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0112, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 91.9939, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.351, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.707, 'epoch': 31.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.05258641391992569, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.979, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.3019, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.17, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.701, 'epoch': 31.0}\n","{'eval_mnli_loss': 7.668882846832275, 'eval_mnli_accuracy': 0.48789599521817095, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.2593, 'eval_mnli_samples_per_second': 53.855, 'eval_mnli_steps_per_second': 1.69, 'epoch': 31.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 12.82470417022705, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0032, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.1719, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.246, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.703, 'epoch': 32.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.019402191042900085, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9932, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.2493, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.201, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.702, 'epoch': 32.0}\n","{'eval_mnli_loss': 8.093835830688477, 'eval_mnli_accuracy': 0.4869994022713688, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.6845, 'eval_mnli_samples_per_second': 53.671, 'eval_mnli_steps_per_second': 1.684, 'epoch': 32.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 13.518975257873535, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0018, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.3752, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.127, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.7, 'epoch': 33.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.010118905454874039, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.996, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0511, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.318, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.706, 'epoch': 33.0}\n","{'eval_mnli_loss': 8.295318603515625, 'eval_mnli_accuracy': 0.4850567842199641, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.85, 'eval_mnli_samples_per_second': 53.6, 'eval_mnli_steps_per_second': 1.682, 'epoch': 33.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 13.258255004882812, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0028, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.3286, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.154, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.7, 'epoch': 34.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.015777673572301865, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9946, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.199, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.231, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.703, 'epoch': 34.0}\n","{'eval_mnli_loss': 8.21270751953125, 'eval_mnli_accuracy': 0.486252241482367, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.8991, 'eval_mnli_samples_per_second': 53.579, 'eval_mnli_steps_per_second': 1.681, 'epoch': 34.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 12.607301712036133, 'eval_hans-lexical_overlap-entailment_accuracy': 0.007, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.2263, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.214, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.702, 'epoch': 35.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.031373217701911926, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9878, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.3991, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.113, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.699, 'epoch': 35.0}\n","{'eval_mnli_loss': 7.997874736785889, 'eval_mnli_accuracy': 0.48670053795576806, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.864, 'eval_mnli_samples_per_second': 53.594, 'eval_mnli_steps_per_second': 1.682, 'epoch': 35.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 11.846973419189453, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0102, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.259, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.195, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.702, 'epoch': 36.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.05524592101573944, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.978, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.3105, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.165, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.701, 'epoch': 36.0}\n","{'eval_mnli_loss': 7.723161697387695, 'eval_mnli_accuracy': 0.4877465630603706, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 125.0844, 'eval_mnli_samples_per_second': 53.5, 'eval_mnli_steps_per_second': 1.679, 'epoch': 36.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 11.016867637634277, 'eval_hans-lexical_overlap-entailment_accuracy': 0.018, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.4384, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.09, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.698, 'epoch': 37.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.09147239476442337, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9672, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.479, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.066, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.698, 'epoch': 37.0}\n","{'eval_mnli_loss': 7.417838096618652, 'eval_mnli_accuracy': 0.48968918111177523, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 125.0722, 'eval_mnli_samples_per_second': 53.505, 'eval_mnli_steps_per_second': 1.679, 'epoch': 37.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 10.20132064819336, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0274, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.4139, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.104, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.699, 'epoch': 38.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.13795174658298492, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.952, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.7216, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 53.925, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.693, 'epoch': 38.0}\n","{'eval_mnli_loss': 7.108367919921875, 'eval_mnli_accuracy': 0.49013747758517634, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 125.261, 'eval_mnli_samples_per_second': 53.424, 'eval_mnli_steps_per_second': 1.676, 'epoch': 38.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 9.466053009033203, 'eval_hans-lexical_overlap-entailment_accuracy': 0.037, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.7247, 'eval_hans-lexical_overlap-entailment_samples_per_second': 53.923, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.693, 'epoch': 39.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.1927150934934616, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9334, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.6925, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 53.942, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.694, 'epoch': 39.0}\n","{'eval_mnli_loss': 6.82753849029541, 'eval_mnli_accuracy': 0.49267782426778245, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 125.4546, 'eval_mnli_samples_per_second': 53.342, 'eval_mnli_steps_per_second': 1.674, 'epoch': 39.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 8.954721450805664, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0444, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.6898, 'eval_hans-lexical_overlap-entailment_samples_per_second': 53.943, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.694, 'epoch': 40.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.23869843780994415, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.9208, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.1612, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.253, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.704, 'epoch': 40.0}\n","{'eval_mnli_loss': 6.6336140632629395, 'eval_mnli_accuracy': 0.4931261207411835, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 124.628, 'eval_mnli_samples_per_second': 53.696, 'eval_mnli_steps_per_second': 1.685, 'epoch': 40.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 9.104738235473633, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0412, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 92.102, 'eval_hans-lexical_overlap-entailment_samples_per_second': 54.288, 'eval_hans-lexical_overlap-entailment_steps_per_second': 1.705, 'epoch': 41.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.21844317018985748, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.926, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 92.0958, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 54.291, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 1.705, 'epoch': 41.0}\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}