{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNIm14C6leowVx0gIGq5D/O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28487,"status":"ok","timestamp":1713839050554,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"},"user_tz":-480},"id":"tx7_kmDqNGwq","outputId":"39009fee-de4c-4741-ec91-ed0dd5a5774e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1713839050554,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"},"user_tz":-480},"id":"Xu36X7TX29Eb","outputId":"d8607765-e8f5-4b3d-ff66-5c5f15200d79"},"outputs":[{"output_type":"stream","name":"stdout","text":["               total        used        free      shared  buff/cache   available\n","Mem:            83Gi       890Mi        78Gi       1.0Mi       4.1Gi        81Gi\n","Swap:             0B          0B          0B\n","Tue Apr 23 02:24:09 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0              44W / 400W |      2MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-48d9c697-2c1a-070c-9f2f-6e65b24d89c0)\n"]}],"source":["# Free colab seems to give different amount of general RAM to different users or even the same users at different times.\n","!free -h\n","\n","# check which nvidia drivers and cuda version is running\n","!nvidia-smi\n","!nvidia-smi -L"]},{"cell_type":"code","source":["# declare env vars\n","%env PROJECT_DIR=/content/drive/My Drive/Education/Master's (GaTech)/Courses/CS7643: Deep Learning/Project/CS7643-Efficient_LLM\n","%env model_name=facebook/opt-125m"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORpj1LFIelPk","executionInfo":{"status":"ok","timestamp":1713839050554,"user_tz":-480,"elapsed":7,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"}},"outputId":"a9c976f2-2884-4452-eeeb-2341d4d9b769"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["env: PROJECT_DIR=/content/drive/My Drive/Education/Master's (GaTech)/Courses/CS7643: Deep Learning/Project/CS7643-Efficient_LLM\n","env: model_name=facebook/opt-125m\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86231,"status":"ok","timestamp":1713839136783,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"},"user_tz":-480},"id":"ZpL2uwCnODEY","outputId":"3e7682cc-5706-4e6b-f467-a05af5712388"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n","Requirement already satisfied: torch==2.2.1+cu121 in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: torchvision==0.17.1+cu121 in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n","Requirement already satisfied: torchaudio==2.2.1+cu121 in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1+cu121)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1+cu121)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1+cu121)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1+cu121)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1+cu121) (2.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.1+cu121) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.1+cu121) (9.4.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1+cu121)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1+cu121) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1+cu121) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["\n","# need to match the system-wide installed cuda-11 for deepspeed to compile\n","# so install the matching pytorch\n","\n","# pt-1.8.1 works too\n","# !pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","# pt-1.11\n","#!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n","!pip install -U torch==2.2.1+cu121 torchvision==0.17.1+cu121 torchaudio==2.2.1+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41052,"status":"ok","timestamp":1713839177832,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"},"user_tz":-480},"id":"F3BEur1nRsJ8","outputId":"71c8a59f-76e8-42d1-9530-f5364c14e699"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/microsoft/deepspeed\n","  Cloning https://github.com/microsoft/deepspeed to /tmp/pip-req-build-jkauw_i6\n","  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/deepspeed /tmp/pip-req-build-jkauw_i6\n","  Resolved https://github.com/microsoft/deepspeed to commit c66bc4269e9484b6e57d6f5521df02c70d399246\n","  Running command git submodule update --init --recursive -q\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting hjson (from deepspeed==0.14.2+c66bc426)\n","  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ninja (from deepspeed==0.14.2+c66bc426)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.2+c66bc426) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.2+c66bc426) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.2+c66bc426) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.2+c66bc426) (9.0.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.2+c66bc426) (2.7.0)\n","Collecting pynvml (from deepspeed==0.14.2+c66bc426)\n","  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.2+c66bc426) (2.2.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.2+c66bc426) (4.66.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.2+c66bc426) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.2+c66bc426) (2.18.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.2+c66bc426) (4.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (3.13.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.14.2+c66bc426) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.14.2+c66bc426) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed==0.14.2+c66bc426) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed==0.14.2+c66bc426) (1.3.0)\n","Building wheels for collected packages: deepspeed\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.14.2+c66bc426-py3-none-any.whl size=1431560 sha256=731c70e579f4853009901b9d6cd6257216ddd0f57f3644031bf82d51e0745422\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-f659gas0/wheels/c7/2a/60/6cd1be5e9093337b6243efab085ade35b787b5c4c1aaf99387\n","Successfully built deepspeed\n","Installing collected packages: ninja, hjson, pynvml, deepspeed\n","Successfully installed deepspeed-0.14.2+c66bc426 hjson-3.1.0 ninja-1.11.1.1 pynvml-11.5.0\n"]}],"source":["# either install the release\n","#!pip install deepspeed\n","# or the master\n","\n","!pip install -U git+https://github.com/microsoft/deepspeed\n","# !pip install -U git+https://github.com/microsoft/DeepSpeed/tree/v0.8.3\n","\n","\n","# remove any previously cached deepspeed objects as they can be incompatible with this new build\n","#!rm -r /root/.cache/torch_extensions/"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17521,"status":"ok","timestamp":1713839195341,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"},"user_tz":-480},"id":"pcxd8zEPOd_N","outputId":"1e594317-70b1-4e58-c197-b0d5856293e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate==0.3.0\n","  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.30.0\n","  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate==0.27.2\n","  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (1.25.2)\n","Collecting dill (from evaluate==0.3.0)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (4.66.2)\n","Collecting xxhash (from evaluate==0.3.0)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from evaluate==0.3.0)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (24.0)\n","Collecting responses<0.19 (from evaluate==0.3.0)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (3.13.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2023.12.25)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.4.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (2.2.1+cu121)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.7.0 (from evaluate==0.3.0)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.3.0) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (2024.2.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.3.0) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n","Installing collected packages: tokenizers, xxhash, dill, responses, multiprocess, huggingface-hub, transformers, datasets, accelerate, evaluate\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.40.0\n","    Uninstalling transformers-4.40.0:\n","      Successfully uninstalled transformers-4.40.0\n","Successfully installed accelerate-0.27.2 datasets-2.19.0 dill-0.3.8 evaluate-0.3.0 huggingface-hub-0.22.2 multiprocess-0.70.16 responses-0.18.0 tokenizers-0.13.3 transformers-4.30.0 xxhash-3.4.1\n"]}],"source":["!pip install -U datasets evaluate==0.3.0 transformers==4.30.0 accelerate==0.27.2"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1046,"status":"ok","timestamp":1713839196385,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"},"user_tz":-480},"id":"dGOBukj1anK1","outputId":"0e8977ba-d1d5-4f33-a181-747d4d56b66b"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","True\n"]}],"source":["import torch\n","print(torch.cuda.device_count())\n","print(torch.cuda.is_available())"]},{"cell_type":"code","source":["# ICL experiment\n","# bash $PROJECT_DIR/scripts/in_context/mnli/run_gpt3.sh mnli 16 facebook/opt-30b 1 60000\n","# Train custom model\n","#!python eval.py --task_name mnli --num_shots 2 --model_name_or_path facebook/opt-125m --pattern \"{text1} {text2} ?\" --target_prefix \" \" --target_tokens \"ĠYes,ĠNo\" --separate_shots_by \"\\n\\n\" --group \"minimal\" --max_seq_length 2048 --output_dir \"./output\" --do_eval --eval_task_name \"hans\" --per_device_eval_batch_size 10 --balanced --shuffle --seed 0 --data_seed 0 --dataset_cache_dir \"./hf_dataset\" --cache_dir \"./hf_model\" --report_to \"none\"\n","!python \"${PROJECT_DIR}/eval.py\" \\\n","        --model_name_or_path $model_name \\\n","        --cache_dir \"./hf_model\" \\\n","        --task_name mnli \\\n","        --pattern \"{text1} question: {text2} Yes or No?\" \\\n","        --target_prefix \" answer: \" \\\n","        --target_tokens \"ĠYes,ĠNo\" \\\n","        --separate_shots_by \"\\n\\n\" \\\n","        --group \"gpt-3\" \\\n","        --dataset_cache_dir \"./hf_dataset\" \\\n","        --max_seq_length 2048 \\\n","        --output_dir \"./output\" \\\n","        --do_eval  \\\n","        --eval_task_name \"hans\" \\\n","        --per_device_eval_batch_size 10 \\\n","        --num_shots 16 \\\n","        --balanced \\\n","        --shuffle \\\n","        --fp16 \\\n","        --seed 0 \\\n","        --data_seed 0 \\\n","        --report_to \"none\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6W9aRrx1CzLn","outputId":"0844b3be-494e-49bd-9ca3-8714ab3ecbd1","executionInfo":{"status":"ok","timestamp":1713082223848,"user_tz":-480,"elapsed":1583567,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-14 07:44:04.640439: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-14 07:44:04.640496: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-14 07:44:04.641949: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-14 07:44:05.845600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[2024-04-14 07:44:12,105] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n","\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n","\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n","\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n","\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n","\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n","\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n","04/14/2024 07:44:14 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n","Downloading readme: 100% 35.3k/35.3k [00:00<00:00, 50.3MB/s]\n","Downloading data: 100% 52.2M/52.2M [00:04<00:00, 12.8MB/s]\n","Downloading data: 100% 1.21M/1.21M [00:00<00:00, 4.73MB/s]\n","Downloading data: 100% 1.25M/1.25M [00:00<00:00, 4.73MB/s]\n","Downloading data: 100% 1.22M/1.22M [00:00<00:00, 2.99MB/s]\n","Downloading data: 100% 1.26M/1.26M [00:00<00:00, 5.24MB/s]\n","Generating train split: 100% 392702/392702 [00:00<00:00, 837551.69 examples/s]\n","Generating validation_matched split: 100% 9815/9815 [00:00<00:00, 764094.02 examples/s]\n","Generating validation_mismatched split: 100% 9832/9832 [00:00<00:00, 789523.60 examples/s]\n","Generating test_matched split: 100% 9796/9796 [00:00<00:00, 824733.58 examples/s]\n","Generating test_mismatched split: 100% 9847/9847 [00:00<00:00, 842677.54 examples/s]\n","Filter: 100% 392702/392702 [00:01<00:00, 205088.41 examples/s]\n","Filter: 100% 9815/9815 [00:00<00:00, 193519.86 examples/s]\n","Filter: 100% 9832/9832 [00:00<00:00, 202080.65 examples/s]\n","Filter: 100% 9796/9796 [00:00<00:00, 195571.41 examples/s]\n","Filter: 100% 9847/9847 [00:00<00:00, 188582.71 examples/s]\n","Map: 100% 261802/261802 [00:25<00:00, 10142.69 examples/s]\n","Map: 100% 6692/6692 [00:00<00:00, 10807.32 examples/s]\n","Map: 100% 6703/6703 [00:00<00:00, 10814.52 examples/s]\n","Map: 100% 9796/9796 [00:00<00:00, 11173.22 examples/s]\n","Map: 100% 9847/9847 [00:00<00:00, 11352.24 examples/s]\n","Casting the dataset: 100% 261802/261802 [00:00<00:00, 2378576.93 examples/s]\n","Casting the dataset: 100% 6692/6692 [00:00<00:00, 1170535.98 examples/s]\n","Casting the dataset: 100% 6703/6703 [00:00<00:00, 1175646.89 examples/s]\n","Casting the dataset: 100% 9796/9796 [00:00<00:00, 1407295.59 examples/s]\n","Casting the dataset: 100% 9847/9847 [00:00<00:00, 1423005.50 examples/s]\n","Downloading data: 100% 3.14M/3.14M [00:01<00:00, 2.50MB/s]\n","Downloading data: 100% 3.14M/3.14M [00:01<00:00, 2.92MB/s]\n","Generating train split: 100% 30000/30000 [00:00<00:00, 496482.89 examples/s]\n","Generating validation split: 100% 30000/30000 [00:00<00:00, 510929.33 examples/s]\n","Filter: 100% 30000/30000 [00:00<00:00, 79064.27 examples/s]\n","Filter: 100% 10000/10000 [00:00<00:00, 27643.63 examples/s]\n","Filter: 100% 10000/10000 [00:00<00:00, 27154.96 examples/s]\n","config.json: 100% 651/651 [00:00<00:00, 3.17MB/s]\n","tokenizer_config.json: 100% 685/685 [00:00<00:00, 3.28MB/s]\n","vocab.json: 100% 899k/899k [00:00<00:00, 2.74MB/s]\n","merges.txt: 100% 456k/456k [00:00<00:00, 1.85MB/s]\n","special_tokens_map.json: 100% 441/441 [00:00<00:00, 2.47MB/s]\n","pytorch_model.bin: 100% 251M/251M [00:00<00:00, 349MB/s]\n","generation_config.json: 100% 137/137 [00:00<00:00, 625kB/s]\n","{'entailment': 0, 'contradiction': 1}\n","{0: 'entailment', 1: 'contradiction'}\n","Filter: 100% 261802/261802 [00:01<00:00, 200636.73 examples/s]\n","Filter: 100% 261802/261802 [00:01<00:00, 206511.73 examples/s]\n","Filter: 100% 261802/261802 [00:01<00:00, 196426.61 examples/s]\n","[2, 1121, 5, 4619, 687, 4908, 15044, 6, 2782, 7373, 11047, 5, 3521, 9, 10332, 8, 34822, 1684, 1230, 782, 6, 8, 98, 5, 1947, 9, 2482, 22181, 8, 3713, 2457, 267, 1630, 5191, 4373, 11, 5, 76, 883, 612, 741, 4, 438, 4, 2156, 2351, 10, 25492, 190, 55, 3319, 87, 14, 9, 5, 30058, 1253, 54, 376, 423, 4, 864, 35, 20, 30058, 1253, 4209, 5, 36005, 25492, 14, 14344, 106, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 2895, 9, 5, 2261, 6, 19, 5, 8219, 9, 3516, 6, 54, 2282, 75, 648, 551, 10, 1413, 6, 67, 224, 14, 1402, 2189, 6, 217, 1131, 8, 613, 335, 6, 197, 28, 4371, 30, 2309, 4, 864, 35, 3516, 2282, 75, 551, 10, 1413, 15, 5, 696, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 42666, 99, 16, 110, 676, 57, 19, 101, 109, 47, 33, 7497, 6774, 14, 697, 19, 47, 50, 33, 3033, 19, 110, 1041, 50, 402, 101, 14, 864, 35, 3945, 70, 110, 6774, 1462, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1185, 581, 1819, 465, 10, 183, 18, 825, 7, 13830, 1671, 8907, 10, 182, 2814, 464, 31, 5, 16476, 2297, 1571, 9, 103, 9, 5, 1947, 3027, 4, 864, 35, 13830, 1671, 8907, 6822, 10, 2579, 5709, 7, 5, 81, 26195, 2297, 1571, 9, 97, 1947, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 24877, 1415, 62, 23, 123, 6, 5, 7705, 5764, 2227, 11, 69, 652, 4, 1437, 864, 35, 2708, 18, 652, 3491, 3195, 25, 79, 1415, 62, 23, 123, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 4297, 9574, 82, 82, 2025, 75, 14, 29804, 864, 35, 404, 82, 32, 2778, 29804, 4, 1437, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 9635, 1825, 6, 8963, 12, 2619, 17844, 73, 574, 25, 8316, 6335, 246, 4397, 3457, 19, 211, 4, 181, 7590, 1178, 341, 30389, 12, 9635, 16689, 620, 405, 13735, 514, 36, 30033, 864, 35, 20, 3457, 341, 1823, 12, 9635, 16689, 620, 405, 13735, 514, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 133, 3969, 694, 3827, 1030, 544, 13, 9473, 28207, 82, 54, 240, 244, 19, 35447, 4643, 6, 3469, 9531, 6, 8, 97, 284, 488, 3510, 4, 864, 35, 4619, 28207, 82, 58, 1286, 1030, 544, 30, 5, 3969, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 14541, 52, 4395, 75, 2120, 7, 4442, 5, 301, 9, 358, 1736, 4, 864, 35, 166, 197, 4442, 5, 301, 9, 358, 809, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 26724, 877, 16, 11401, 43709, 11835, 14, 38, 4036, 2598, 18118, 7, 3116, 1736, 33605, 16849, 13, 349, 3149, 9, 5, 1811, 5223, 7150, 5672, 9, 17450, 45248, 12, 31230, 6801, 1704, 12, 4310, 2691, 23149, 480, 102, 651, 14, 38, 23426, 8, 13, 61, 38, 1665, 25, 937, 4474, 4, 864, 35, 38, 1665, 25, 10, 937, 4474, 13, 10, 3228, 12, 33313, 651, 9, 1364, 4, 1437, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 1213, 439, 124, 8, 7264, 6, 5507, 19143, 6, 20752, 6, 10720, 6, 25609, 6, 8, 53, 2577, 19, 39, 28702, 4, 864, 35, 5507, 21, 634, 39, 34281, 8, 1730, 7, 908, 4, 1437, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 133, 138, 67, 1523, 10, 1186, 9, 4828, 8171, 1058, 6, 540, 4828, 12120, 6, 8, 14110, 12906, 5137, 1767, 4, 864, 35, 8575, 337, 8171, 1058, 16, 45, 65, 9, 5, 518, 1661, 30, 5, 138, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 13841, 1493, 115, 47, 2999, 159, 81, 68, 3248, 6, 151, 8, 697, 215, 10, 4267, 12, 3743, 8066, 116, 864, 35, 2612, 64, 75, 47, 697, 4558, 8, 146, 418, 396, 519, 23352, 70, 5, 86, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1708, 89, 24, 16, 6, 79, 64, 1137, 47, 1085, 72, 15966, 22, 1708, 596, 6, 313, 116, 1437, 864, 35, 125, 89, 24, 16, 6, 79, 34, 45, 11040, 7, 224, 4, 125, 596, 313, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 23007, 6073, 44444, 4, 864, 35, 44444, 227, 3806, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 3056, 939, 109, 24, 70, 1437, 37463, 4420, 939, 939, 860, 7, 1733, 37463, 37463, 10, 16090, 5671, 8, 864, 35, 38, 348, 393, 1381, 127, 865, 23, 10, 16090, 5671, 131, 16, 24, 543, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","2048\n","Casting the dataset: 100% 6692/6692 [00:00<00:00, 14683.02 examples/s]\n","Casting the dataset: 100% 5000/5000 [00:00<00:00, 9530.53 examples/s]\n","Casting the dataset: 100% 5000/5000 [00:00<00:00, 9423.50 examples/s]\n","Running tokenizer on dataset: 100% 6692/6692 [00:58<00:00, 113.57 examples/s]\n","Running tokenizer on dataset: 100% 5000/5000 [00:43<00:00, 113.91 examples/s]\n","Running tokenizer on dataset: 100% 5000/5000 [00:43<00:00, 114.72 examples/s]\n","Filter: 100% 6692/6692 [00:24<00:00, 276.12 examples/s]\n","Filter: 100% 5000/5000 [00:18<00:00, 276.55 examples/s]\n","Filter: 100% 5000/5000 [00:18<00:00, 277.11 examples/s]\n","100% 670/670 [08:12<00:00,  1.36it/s]\n","100% 500/500 [06:06<00:00,  1.36it/s]\n","100% 500/500 [06:06<00:00,  1.37it/s]\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9rk40w0OPMi","executionInfo":{"status":"ok","timestamp":1713809301376,"user_tz":-480,"elapsed":2183589,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"}},"outputId":"24bf37e2-fd1c-4259-8939-0082340ca378"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-04-22 16:56:43,317] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n","\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n","\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n","\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n","\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n","\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n","\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n","Sample 98 of the training set: {'premise': \"you know Uncle Sam but i've always thought that they were slow  as far as outside of the government you know\", 'hypothesis': \"My personal opinion is that they've always been fast.\", 'label': 440, 'idx': 93643, 'input_ids': [2, 6968, 216, 25848, 1960, 53, 939, 348, 460, 802, 14, 51, 58, 2635, 1437, 25, 444, 25, 751, 9, 5, 168, 47, 216, 1308, 1081, 2979, 16, 14, 51, 348, 460, 57, 1769, 4, 17487, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'soft_prompt_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_tokens': ['</s>', 'you', 'Ġknow', 'ĠUncle', 'ĠSam', 'Ġbut', 'Ġi', \"'ve\", 'Ġalways', 'Ġthought', 'Ġthat', 'Ġthey', 'Ġwere', 'Ġslow', 'Ġ', 'Ġas', 'Ġfar', 'Ġas', 'Ġoutside', 'Ġof', 'Ġthe', 'Ġgovernment', 'Ġyou', 'Ġknow', 'ĠMy', 'Ġpersonal', 'Ġopinion', 'Ġis', 'Ġthat', 'Ġthey', \"'ve\", 'Ġalways', 'Ġbeen', 'Ġfast', '.', 'Ġ?', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'input_text': \"</s>you know Uncle Sam but i've always thought that they were slow  as far as outside of the government you know My personal opinion is that they've always been fast.?<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\", 'label_text': 'contradiction'}.\n","Trainable parameters: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias']\n","override self.deepspeed to False\n","{'eval_hans-lexical_overlap-entailment_loss': 5.784818172454834, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-entailment_runtime': 31.5117, 'eval_hans-lexical_overlap-entailment_samples_per_second': 158.671, 'eval_hans-lexical_overlap-entailment_steps_per_second': 15.867, 'epoch': 1.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 5.430394649505615, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 1.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2243, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.43, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.543, 'epoch': 1.0}\n","{'eval_mnli_loss': 6.188199520111084, 'eval_mnli_accuracy': 0.0, 'eval_mnli_frac_non_target_tokens': 1.0, 'eval_mnli_runtime': 42.3368, 'eval_mnli_samples_per_second': 158.066, 'eval_mnli_steps_per_second': 15.825, 'epoch': 1.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 3.2870023250579834, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0008, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.988, 'eval_hans-lexical_overlap-entailment_runtime': 30.2119, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.498, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.55, 'epoch': 2.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.092254638671875, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0078, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.9914, 'eval_hans-lexical_overlap-contradiction_runtime': 30.216, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.475, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.548, 'epoch': 2.0}\n","{'eval_mnli_loss': 3.2854726314544678, 'eval_mnli_accuracy': 0.04049611476389719, 'eval_mnli_frac_non_target_tokens': 0.9296174536760311, 'eval_mnli_runtime': 40.6928, 'eval_mnli_samples_per_second': 164.452, 'eval_mnli_steps_per_second': 16.465, 'epoch': 2.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.0611213445663452, 'eval_hans-lexical_overlap-entailment_accuracy': 0.382, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0002, 'eval_hans-lexical_overlap-entailment_runtime': 30.2583, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.244, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.524, 'epoch': 3.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.9648021459579468, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.6216, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2586, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.242, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.524, 'epoch': 3.0}\n","{'eval_mnli_loss': 0.9924833178520203, 'eval_mnli_accuracy': 0.5390017931858936, 'eval_mnli_frac_non_target_tokens': 0.017035265989240884, 'eval_mnli_runtime': 40.7557, 'eval_mnli_samples_per_second': 164.198, 'eval_mnli_steps_per_second': 16.439, 'epoch': 3.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.56354159116745, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9456, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1954, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.588, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.559, 'epoch': 4.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 0.9769132733345032, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0684, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2452, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.316, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.532, 'epoch': 4.0}\n","{'eval_mnli_loss': 0.7282513976097107, 'eval_mnli_accuracy': 0.5848774656306037, 'eval_mnli_frac_non_target_tokens': 0.0022414823670053796, 'eval_mnli_runtime': 40.664, 'eval_mnli_samples_per_second': 164.568, 'eval_mnli_steps_per_second': 16.476, 'epoch': 4.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.3749244213104248, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.204, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.541, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.554, 'epoch': 5.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.3313244581222534, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1756, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.697, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.57, 'epoch': 5.0}\n","{'eval_mnli_loss': 0.658003032207489, 'eval_mnli_accuracy': 0.6655708308427973, 'eval_mnli_frac_non_target_tokens': 0.0019426180514046623, 'eval_mnli_runtime': 40.6223, 'eval_mnli_samples_per_second': 164.737, 'eval_mnli_steps_per_second': 16.493, 'epoch': 5.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.12421394139528275, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9964, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0036, 'eval_hans-lexical_overlap-entailment_runtime': 30.2013, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.556, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.556, 'epoch': 6.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.8564682006835938, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0016, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1711, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.722, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.572, 'epoch': 6.0}\n","{'eval_mnli_loss': 0.671634316444397, 'eval_mnli_accuracy': 0.6772265391512253, 'eval_mnli_frac_non_target_tokens': 0.0022414823670053796, 'eval_mnli_runtime': 40.6281, 'eval_mnli_samples_per_second': 164.713, 'eval_mnli_steps_per_second': 16.491, 'epoch': 6.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.09298879653215408, 'eval_hans-lexical_overlap-entailment_accuracy': 0.998, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1567, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.8, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.58, 'epoch': 7.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.045727014541626, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0032, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2377, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.356, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.536, 'epoch': 7.0}\n","{'eval_mnli_loss': 0.7523620128631592, 'eval_mnli_accuracy': 0.6649731022115959, 'eval_mnli_frac_non_target_tokens': 0.0008965929468021519, 'eval_mnli_runtime': 40.7725, 'eval_mnli_samples_per_second': 164.13, 'eval_mnli_steps_per_second': 16.433, 'epoch': 7.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.025744037702679634, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9992, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0006, 'eval_hans-lexical_overlap-entailment_runtime': 30.2038, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.542, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.554, 'epoch': 8.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 4.992188930511475, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0006, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0004, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2818, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.116, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.512, 'epoch': 8.0}\n","{'eval_mnli_loss': 1.0303047895431519, 'eval_mnli_accuracy': 0.6661685594739988, 'eval_mnli_frac_non_target_tokens': 0.00044829647340107593, 'eval_mnli_runtime': 40.6446, 'eval_mnli_samples_per_second': 164.647, 'eval_mnli_steps_per_second': 16.484, 'epoch': 8.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.005426252726465464, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.292, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.06, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.506, 'epoch': 9.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 7.474343776702881, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.3714, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 164.628, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.463, 'epoch': 9.0}\n","{'eval_mnli_loss': 1.3852806091308594, 'eval_mnli_accuracy': 0.6588463837417813, 'eval_mnli_frac_non_target_tokens': 0.00014943215780035862, 'eval_mnli_runtime': 40.7964, 'eval_mnli_samples_per_second': 164.034, 'eval_mnli_steps_per_second': 16.423, 'epoch': 9.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0006219448405317962, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1923, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.605, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.56, 'epoch': 10.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 10.903267860412598, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1879, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.63, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.563, 'epoch': 10.0}\n","{'eval_mnli_loss': 1.9527636766433716, 'eval_mnli_accuracy': 0.6710998206814106, 'eval_mnli_frac_non_target_tokens': 0.00014943215780035862, 'eval_mnli_runtime': 40.6633, 'eval_mnli_samples_per_second': 164.571, 'eval_mnli_steps_per_second': 16.477, 'epoch': 10.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.00599150825291872, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9984, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1869, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.635, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.563, 'epoch': 11.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 13.848678588867188, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0024, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1925, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.604, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.56, 'epoch': 11.0}\n","{'eval_mnli_loss': 3.58069109916687, 'eval_mnli_accuracy': 0.6446503287507471, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6132, 'eval_mnli_samples_per_second': 164.774, 'eval_mnli_steps_per_second': 16.497, 'epoch': 11.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.013911211863160133, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9966, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1608, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.778, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.578, 'epoch': 12.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 16.335569381713867, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.005, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1507, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.834, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.583, 'epoch': 12.0}\n","{'eval_mnli_loss': 6.0416765213012695, 'eval_mnli_accuracy': 0.6049013747758517, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6483, 'eval_mnli_samples_per_second': 164.632, 'eval_mnli_steps_per_second': 16.483, 'epoch': 12.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 2.5769273293008155e-07, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1873, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.632, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.563, 'epoch': 13.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.14021110534668, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2449, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.317, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.532, 'epoch': 13.0}\n","{'eval_mnli_loss': 4.887323379516602, 'eval_mnli_accuracy': 0.6699043634190077, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6085, 'eval_mnli_samples_per_second': 164.793, 'eval_mnli_steps_per_second': 16.499, 'epoch': 13.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.0065916285384446e-05, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1786, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.68, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.568, 'epoch': 14.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.971515655517578, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.157, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.799, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.58, 'epoch': 14.0}\n","{'eval_mnli_loss': 5.509922504425049, 'eval_mnli_accuracy': 0.6528690974297668, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.646, 'eval_mnli_samples_per_second': 164.641, 'eval_mnli_steps_per_second': 16.484, 'epoch': 14.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0003589005791582167, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.282, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.115, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.511, 'epoch': 15.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.36424446105957, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0006, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1713, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.72, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.572, 'epoch': 15.0}\n","{'eval_mnli_loss': 5.5190629959106445, 'eval_mnli_accuracy': 0.6622833233711894, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6257, 'eval_mnli_samples_per_second': 164.723, 'eval_mnli_steps_per_second': 16.492, 'epoch': 15.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.06250669807195663, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9888, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2273, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.413, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.541, 'epoch': 16.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.102968215942383, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.01, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1888, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.624, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.562, 'epoch': 16.0}\n","{'eval_mnli_loss': 6.347175121307373, 'eval_mnli_accuracy': 0.627465630603706, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6455, 'eval_mnli_samples_per_second': 164.643, 'eval_mnli_steps_per_second': 16.484, 'epoch': 16.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.018145067617297173, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9976, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1705, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.725, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.572, 'epoch': 17.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.261795043945312, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0044, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1955, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.587, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.559, 'epoch': 17.0}\n","{'eval_mnli_loss': 6.1192169189453125, 'eval_mnli_accuracy': 0.649581589958159, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6741, 'eval_mnli_samples_per_second': 164.527, 'eval_mnli_steps_per_second': 16.472, 'epoch': 17.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.005912150721997023, 'eval_hans-lexical_overlap-entailment_accuracy': 0.999, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2194, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.457, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.546, 'epoch': 18.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.406286239624023, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0016, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2086, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.516, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.552, 'epoch': 18.0}\n","{'eval_mnli_loss': 5.612086772918701, 'eval_mnli_accuracy': 0.6646742378959952, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6414, 'eval_mnli_samples_per_second': 164.66, 'eval_mnli_steps_per_second': 16.486, 'epoch': 18.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.02150546945631504, 'eval_hans-lexical_overlap-entailment_accuracy': 0.996, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.314, 'eval_hans-lexical_overlap-entailment_samples_per_second': 164.941, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.494, 'epoch': 19.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.65447425842285, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0038, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1808, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.668, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.567, 'epoch': 19.0}\n","{'eval_mnli_loss': 6.488889694213867, 'eval_mnli_accuracy': 0.6207411835026898, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6, 'eval_mnli_samples_per_second': 164.828, 'eval_mnli_steps_per_second': 16.502, 'epoch': 19.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 3.454477700870484e-05, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1634, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.764, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.576, 'epoch': 20.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.969161987304688, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0006, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1365, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.912, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.591, 'epoch': 20.0}\n","{'eval_mnli_loss': 5.518611431121826, 'eval_mnli_accuracy': 0.663329348475792, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6265, 'eval_mnli_samples_per_second': 164.72, 'eval_mnli_steps_per_second': 16.492, 'epoch': 20.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 7.339964014363431e-08, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1184, 'eval_hans-lexical_overlap-entailment_samples_per_second': 166.011, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.601, 'epoch': 21.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.014238357543945, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1838, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.652, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.565, 'epoch': 21.0}\n","{'eval_mnli_loss': 5.324139595031738, 'eval_mnli_accuracy': 0.6673640167364017, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.5994, 'eval_mnli_samples_per_second': 164.83, 'eval_mnli_steps_per_second': 16.503, 'epoch': 21.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 4.0531150657940884e-10, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.163, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.766, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.577, 'epoch': 22.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.154335021972656, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1333, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.929, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.593, 'epoch': 22.0}\n","{'eval_mnli_loss': 5.326109886169434, 'eval_mnli_accuracy': 0.6734907352062164, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.5727, 'eval_mnli_samples_per_second': 164.939, 'eval_mnli_steps_per_second': 16.514, 'epoch': 22.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0008248012745752931, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9996, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1648, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.756, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.576, 'epoch': 23.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.182926177978516, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.001, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1546, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.812, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.581, 'epoch': 23.0}\n","{'eval_mnli_loss': 6.318723678588867, 'eval_mnli_accuracy': 0.6356843992827257, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6194, 'eval_mnli_samples_per_second': 164.749, 'eval_mnli_steps_per_second': 16.495, 'epoch': 23.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0016713354270905256, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9996, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1411, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.886, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.589, 'epoch': 24.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.21404457092285, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.001, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1845, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.648, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.565, 'epoch': 24.0}\n","{'eval_mnli_loss': 6.304898738861084, 'eval_mnli_accuracy': 0.6434548714883442, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.609, 'eval_mnli_samples_per_second': 164.791, 'eval_mnli_steps_per_second': 16.499, 'epoch': 24.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 5.091535513201961e-06, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2265, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.418, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.542, 'epoch': 25.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.155879974365234, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0008, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2262, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.419, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.542, 'epoch': 25.0}\n","{'eval_mnli_loss': 5.705129623413086, 'eval_mnli_accuracy': 0.6552600119545726, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6594, 'eval_mnli_samples_per_second': 164.587, 'eval_mnli_steps_per_second': 16.478, 'epoch': 25.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2063, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.528, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.553, 'epoch': 26.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.914630889892578, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2618, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.225, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.522, 'epoch': 26.0}\n","{'eval_mnli_loss': 5.879867076873779, 'eval_mnli_accuracy': 0.6603407053197848, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6444, 'eval_mnli_samples_per_second': 164.648, 'eval_mnli_steps_per_second': 16.484, 'epoch': 26.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 4.363040151389441e-09, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1995, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.566, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.557, 'epoch': 27.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.884260177612305, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2555, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.259, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.526, 'epoch': 27.0}\n","{'eval_mnli_loss': 5.7270188331604, 'eval_mnli_accuracy': 0.6628810520023909, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6876, 'eval_mnli_samples_per_second': 164.473, 'eval_mnli_steps_per_second': 16.467, 'epoch': 27.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 9.536742923144104e-11, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2168, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.471, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.547, 'epoch': 28.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.087909698486328, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2464, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.309, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.531, 'epoch': 28.0}\n","{'eval_mnli_loss': 5.442840099334717, 'eval_mnli_accuracy': 0.6681111775254035, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6626, 'eval_mnli_samples_per_second': 164.574, 'eval_mnli_steps_per_second': 16.477, 'epoch': 28.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 2.384185730786026e-11, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2452, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.316, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.532, 'epoch': 29.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.06283187866211, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1509, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.833, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.583, 'epoch': 29.0}\n","{'eval_mnli_loss': 5.612177848815918, 'eval_mnli_accuracy': 0.667065152420801, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.5727, 'eval_mnli_samples_per_second': 164.939, 'eval_mnli_steps_per_second': 16.514, 'epoch': 29.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0016594214830547571, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9996, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1206, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.999, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.6, 'epoch': 30.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.676467895507812, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.001, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2456, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.313, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.531, 'epoch': 30.0}\n","{'eval_mnli_loss': 5.584412097930908, 'eval_mnli_accuracy': 0.6625821876867902, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6816, 'eval_mnli_samples_per_second': 164.497, 'eval_mnli_steps_per_second': 16.469, 'epoch': 30.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 6.648605932468854e-08, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2225, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.44, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.544, 'epoch': 31.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.76251983642578, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2056, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.532, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.553, 'epoch': 31.0}\n","{'eval_mnli_loss': 5.457004547119141, 'eval_mnli_accuracy': 0.6746861924686193, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.614, 'eval_mnli_samples_per_second': 164.771, 'eval_mnli_steps_per_second': 16.497, 'epoch': 31.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 8.417657954851165e-05, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2739, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.159, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.516, 'epoch': 32.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.810062408447266, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0008, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1886, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.625, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.563, 'epoch': 32.0}\n","{'eval_mnli_loss': 5.611255645751953, 'eval_mnli_accuracy': 0.6699043634190077, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6455, 'eval_mnli_samples_per_second': 164.643, 'eval_mnli_steps_per_second': 16.484, 'epoch': 32.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 7.22766912986117e-08, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.178, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.684, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.568, 'epoch': 33.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.94240379333496, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0006, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1743, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.704, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.57, 'epoch': 33.0}\n","{'eval_mnli_loss': 5.5316162109375, 'eval_mnli_accuracy': 0.6682606096832038, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6588, 'eval_mnli_samples_per_second': 164.589, 'eval_mnli_steps_per_second': 16.479, 'epoch': 33.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.5735589498078184e-09, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2039, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.541, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.554, 'epoch': 34.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 20.07999610900879, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2466, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.308, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.531, 'epoch': 34.0}\n","{'eval_mnli_loss': 5.567528247833252, 'eval_mnli_accuracy': 0.6646742378959952, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6651, 'eval_mnli_samples_per_second': 164.564, 'eval_mnli_steps_per_second': 16.476, 'epoch': 34.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 2.1219199730637683e-09, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1766, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.691, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.569, 'epoch': 35.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.765247344970703, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2801, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.125, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.513, 'epoch': 35.0}\n","{'eval_mnli_loss': 5.527456760406494, 'eval_mnli_accuracy': 0.6645248057381948, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.7227, 'eval_mnli_samples_per_second': 164.331, 'eval_mnli_steps_per_second': 16.453, 'epoch': 35.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 7.152555769884827e-10, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2312, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.392, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.539, 'epoch': 36.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.735624313354492, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2269, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.415, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.542, 'epoch': 36.0}\n","{'eval_mnli_loss': 5.486204147338867, 'eval_mnli_accuracy': 0.6646742378959952, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6946, 'eval_mnli_samples_per_second': 164.444, 'eval_mnli_steps_per_second': 16.464, 'epoch': 36.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 3.57627816249817e-10, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.2251, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.425, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.543, 'epoch': 37.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.692642211914062, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0002, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.2546, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.264, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.526, 'epoch': 37.0}\n","{'eval_mnli_loss': 5.511646270751953, 'eval_mnli_accuracy': 0.6646742378959952, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.7434, 'eval_mnli_samples_per_second': 164.247, 'eval_mnli_steps_per_second': 16.444, 'epoch': 37.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 1.015641437618342e-08, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.271, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.174, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.517, 'epoch': 38.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.795372009277344, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0004, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1664, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.748, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.575, 'epoch': 38.0}\n","{'eval_mnli_loss': 5.496927738189697, 'eval_mnli_accuracy': 0.6642259414225942, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6047, 'eval_mnli_samples_per_second': 164.808, 'eval_mnli_steps_per_second': 16.501, 'epoch': 38.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.00022045927471481264, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.159, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.788, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.579, 'epoch': 39.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.674272537231445, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0008, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1762, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.693, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.569, 'epoch': 39.0}\n","{'eval_mnli_loss': 5.590031623840332, 'eval_mnli_accuracy': 0.6657202630005977, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6671, 'eval_mnli_samples_per_second': 164.556, 'eval_mnli_steps_per_second': 16.475, 'epoch': 39.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.00029230533982627094, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 30.1594, 'eval_hans-lexical_overlap-entailment_samples_per_second': 165.786, 'eval_hans-lexical_overlap-entailment_steps_per_second': 16.579, 'epoch': 40.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 19.63975715637207, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.001, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 30.1425, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 165.879, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 16.588, 'epoch': 40.0}\n","{'eval_mnli_loss': 5.578444957733154, 'eval_mnli_accuracy': 0.6649731022115959, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 40.6608, 'eval_mnli_samples_per_second': 164.581, 'eval_mnli_steps_per_second': 16.478, 'epoch': 40.0}\n","{'train_runtime': 4204.9467, 'train_samples_per_second': 1.218, 'train_steps_per_second': 0.304, 'train_loss': 0.40355687141418456, 'epoch': 40.0}\n","***** train metrics *****\n","  epoch                    =       40.0\n","  train_loss               =     0.4036\n","  train_runtime            = 1:10:04.94\n","  train_samples            =        128\n","  train_samples_per_second =      1.218\n","  train_steps_per_second   =      0.304\n"]}],"source":["# FT experiment (with LM model)\n","# args: task_name, max_train_samples, epochs, warmup_ratio, bsz, num_gpus, learning_rate, model_name_or_path, port\n","#bash $PROJECT_DIR/scripts/pattern_verbalizer_ft/mnli/run.sh mnli 128 40 0.5 4 8 1e-5 facebook/opt-13b 60000\n","\n","\n","!python \"${PROJECT_DIR}/ft.py\" \\\n","            --wandb_project_name llmft-experiments \\\n","            --wandb_group_name vanilla-ft \\\n","            --model_name_or_path $model_name \\\n","            --cache_dir \"./hf_model\" \\\n","            --task_name mnli \\\n","            --pattern \"{text1} {text2} ?\" \\\n","            --target_tokens \"ĠYes,ĠNo\" \\\n","            --dataset_cache_dir \"./hf_dataset\" \\\n","            --max_seq_length 256 \\\n","            --output_dir \"./output\" \\\n","            --overwrite_output_dir \\\n","            --do_train \\\n","            --max_train_samples 128 \\\n","            --per_device_train_batch_size 4 \\\n","            --gradient_accumulation_steps 1 \\\n","            --num_train_epochs 40 \\\n","            --warmup_ratio 0.5 \\\n","            --logging_first_step false \\\n","            --logging_steps -1 \\\n","            --learning_rate 1e-5 \\\n","            --weight_decay 0.0 \\\n","            --do_eval \\\n","            --evaluation_strategy epoch \\\n","            --per_device_eval_batch_size 10 \\\n","            --eval_on_hans \\\n","            --save_strategy no \\\n","            --fp16 \\\n","            --seed 0 \\\n","            --data_seed 0 \\\n","            --report_to \"none\" \\\n","            2> \"${PROJECT_DIR}/logfiles/console.err\""]},{"cell_type":"code","source":["# FT with Context Distillation experiment\n","# args: task_name, max_train_samples, epochs, warmup_ratio, bsz, num_gpus, learning_rate, model_name_or_path, port\n","#bash $PROJECT_DIR/scripts/pattern_verbalizer_ft/mnli/run.sh mnli 128 40 0.5 4 8 1e-5 facebook/opt-13b 60000\n","\n","# --pattern \"{text1} question: {text2} Yes or No?\" \\\n","# --pattern \"{text1} {text2} ?\" \\\n","# --pattern \"{text1} question: {text2} Yes or No? answer:\" \\\n","\n","\n","!python \"${PROJECT_DIR}/ft.py\" \\\n","            --wandb_project_name llmft-experiments \\\n","            --wandb_group_name pattern-verbalizer-ft-context-distillation \\\n","            --model_name_or_path $model_name \\\n","            --cache_dir \"./hf_model\" \\\n","            --task_name mnli \\\n","            --target_tokens \"ĠYes,ĠNo\" \\\n","            --pattern \"{text1} question: {text2} Yes or No?\" \\\n","            --dataset_cache_dir \"./hf_dataset\" \\\n","            --max_seq_length 256 \\\n","            --context_max_seq_length 2048 \\\n","            --output_dir \"./output\" \\\n","            --overwrite_output_dir \\\n","            --do_train \\\n","            --max_train_samples 128 \\\n","            --per_device_train_batch_size 4 \\\n","            --gradient_accumulation_steps 1 \\\n","            --num_train_epochs 40 \\\n","            --warmup_ratio 0.5 \\\n","            --logging_first_step false \\\n","            --logging_steps -1 \\\n","            --learning_rate 1e-5 \\\n","            --weight_decay 0.0 \\\n","            --do_eval \\\n","            --context_distillation_flag True \\\n","            --evaluation_strategy epoch \\\n","            --per_device_eval_batch_size 10 \\\n","            --eval_on_hans \\\n","            --save_strategy no \\\n","            --fp16 \\\n","            --seed 0 \\\n","            --data_seed 0 \\\n","            --num_shots 16 \\\n","            --context_target_tokens \"ĠYes,ĠNo\" \\\n","            --context_pattern \"{text1} question: {text2} Yes or No?\" \\\n","            --separate_shots_by \"\\n\\n\" \\\n","            --target_prefix \" answer: \" \\\n","            --balanced  \\\n","            --shuffle  \\\n","            --report_to \"none\" \\\n","            2> \"${PROJECT_DIR}/logfiles/console_err.txt\""],"metadata":{"id":"bj6ht97gMkh4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"425477b6-332f-4f13-928a-0152f17f73b6","executionInfo":{"status":"ok","timestamp":1713860023353,"user_tz":-480,"elapsed":4444465,"user":{"displayName":"Jia Xiang Lim","userId":"02400975930708755603"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-04-23 06:59:47,785] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n","\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n","\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n","\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n","\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n","\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n","Sample 98 of the training set: {'premise': \"They're some way from the chateau and each other\", 'hypothesis': 'They are not near to each other.', 'label': 3216, 'idx': 192625, 'input_ids': [2, 1213, 214, 103, 169, 31, 5, 1855, 877, 1180, 8, 349, 97, 864, 35, 252, 32, 45, 583, 7, 349, 97, 4, 3216, 50, 440, 116, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'soft_prompt_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_tokens': ['</s>', 'They', \"'re\", 'Ġsome', 'Ġway', 'Ġfrom', 'Ġthe', 'Ġch', 'ate', 'au', 'Ġand', 'Ġeach', 'Ġother', 'Ġquestion', ':', 'ĠThey', 'Ġare', 'Ġnot', 'Ġnear', 'Ġto', 'Ġeach', 'Ġother', '.', 'ĠYes', 'Ġor', 'ĠNo', '?', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'input_text': \"</s>They're some way from the chateau and each other question: They are not near to each other. Yes or No?<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\", 'label_text': 'entailment', 'context_prepended_input_ids': [2, 1121, 5, 4619, 687, 4908, 15044, 6, 2782, 7373, 11047, 5, 3521, 9, 10332, 8, 34822, 1684, 1230, 782, 6, 8, 98, 5, 1947, 9, 2482, 22181, 8, 3713, 2457, 267, 1630, 5191, 4373, 11, 5, 76, 883, 612, 741, 4, 438, 4, 2156, 2351, 10, 25492, 190, 55, 3319, 87, 14, 9, 5, 30058, 1253, 54, 376, 423, 4, 864, 35, 20, 30058, 1253, 4209, 5, 36005, 25492, 14, 14344, 106, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 2895, 9, 5, 2261, 6, 19, 5, 8219, 9, 3516, 6, 54, 2282, 75, 648, 551, 10, 1413, 6, 67, 224, 14, 1402, 2189, 6, 217, 1131, 8, 613, 335, 6, 197, 28, 4371, 30, 2309, 4, 864, 35, 3516, 2282, 75, 551, 10, 1413, 15, 5, 696, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 42666, 99, 16, 110, 676, 57, 19, 101, 109, 47, 33, 7497, 6774, 14, 697, 19, 47, 50, 33, 3033, 19, 110, 1041, 50, 402, 101, 14, 864, 35, 3945, 70, 110, 6774, 1462, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1185, 581, 1819, 465, 10, 183, 18, 825, 7, 13830, 1671, 8907, 10, 182, 2814, 464, 31, 5, 16476, 2297, 1571, 9, 103, 9, 5, 1947, 3027, 4, 864, 35, 13830, 1671, 8907, 6822, 10, 2579, 5709, 7, 5, 81, 26195, 2297, 1571, 9, 97, 1947, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 24877, 1415, 62, 23, 123, 6, 5, 7705, 5764, 2227, 11, 69, 652, 4, 1437, 864, 35, 2708, 18, 652, 3491, 3195, 25, 79, 1415, 62, 23, 123, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 4297, 9574, 82, 82, 2025, 75, 14, 29804, 864, 35, 404, 82, 32, 2778, 29804, 4, 1437, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 9635, 1825, 6, 8963, 12, 2619, 17844, 73, 574, 25, 8316, 6335, 246, 4397, 3457, 19, 211, 4, 181, 7590, 1178, 341, 30389, 12, 9635, 16689, 620, 405, 13735, 514, 36, 30033, 864, 35, 20, 3457, 341, 1823, 12, 9635, 16689, 620, 405, 13735, 514, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 133, 3969, 694, 3827, 1030, 544, 13, 9473, 28207, 82, 54, 240, 244, 19, 35447, 4643, 6, 3469, 9531, 6, 8, 97, 284, 488, 3510, 4, 864, 35, 4619, 28207, 82, 58, 1286, 1030, 544, 30, 5, 3969, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 14541, 52, 4395, 75, 2120, 7, 4442, 5, 301, 9, 358, 1736, 4, 864, 35, 166, 197, 4442, 5, 301, 9, 358, 809, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 26724, 877, 16, 11401, 43709, 11835, 14, 38, 4036, 2598, 18118, 7, 3116, 1736, 33605, 16849, 13, 349, 3149, 9, 5, 1811, 5223, 7150, 5672, 9, 17450, 45248, 12, 31230, 6801, 1704, 12, 4310, 2691, 23149, 480, 102, 651, 14, 38, 23426, 8, 13, 61, 38, 1665, 25, 937, 4474, 4, 864, 35, 38, 1665, 25, 10, 937, 4474, 13, 10, 3228, 12, 33313, 651, 9, 1364, 4, 1437, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 1213, 439, 124, 8, 7264, 6, 5507, 19143, 6, 20752, 6, 10720, 6, 25609, 6, 8, 53, 2577, 19, 39, 28702, 4, 864, 35, 5507, 21, 634, 39, 34281, 8, 1730, 7, 908, 4, 1437, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 133, 138, 67, 1523, 10, 1186, 9, 4828, 8171, 1058, 6, 540, 4828, 12120, 6, 8, 14110, 12906, 5137, 1767, 4, 864, 35, 8575, 337, 8171, 1058, 16, 45, 65, 9, 5, 518, 1661, 30, 5, 138, 4, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 13841, 1493, 115, 47, 2999, 159, 81, 68, 3248, 6, 151, 8, 697, 215, 10, 4267, 12, 3743, 8066, 116, 864, 35, 2612, 64, 75, 47, 697, 4558, 8, 146, 418, 396, 519, 23352, 70, 5, 86, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1708, 89, 24, 16, 6, 79, 64, 1137, 47, 1085, 72, 15966, 22, 1708, 596, 6, 313, 116, 1437, 864, 35, 125, 89, 24, 16, 6, 79, 34, 45, 11040, 7, 224, 4, 125, 596, 313, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 23007, 6073, 44444, 4, 864, 35, 44444, 227, 3806, 4, 3216, 50, 440, 116, 1948, 35, 3216, 37457, 282, 37457, 282, 3056, 939, 109, 24, 70, 1437, 37463, 4420, 939, 939, 860, 7, 1733, 37463, 37463, 10, 16090, 5671, 8, 864, 35, 38, 348, 393, 1381, 127, 865, 23, 10, 16090, 5671, 131, 16, 24, 543, 116, 3216, 50, 440, 116, 1948, 35, 440, 37457, 282, 37457, 282, 1213, 214, 103, 169, 31, 5, 1855, 877, 1180, 8, 349, 97, 864, 35, 252, 32, 45, 583, 7, 349, 97, 4, 3216, 50, 440, 116, 1948, 35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'context_prepended_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","Trainable parameters: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'p_0.model.decoder.embed_tokens.weight', 'p_0.model.decoder.embed_positions.weight']\n","override self.deepspeed to False\n","{'eval_hans-lexical_overlap-entailment_loss': 3.3940374851226807, 'eval_hans-lexical_overlap-entailment_accuracy': 0.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.9962, 'eval_hans-lexical_overlap-entailment_runtime': 25.54, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.771, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.577, 'epoch': 1.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.186446189880371, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0014, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.9986, 'eval_hans-lexical_overlap-contradiction_runtime': 25.569, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.549, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.555, 'epoch': 1.0}\n","{'eval_mnli_loss': 3.8022279739379883, 'eval_mnli_accuracy': 0.021518230723251645, 'eval_mnli_frac_non_target_tokens': 0.9593544530783025, 'eval_mnli_runtime': 34.1632, 'eval_mnli_samples_per_second': 195.883, 'eval_mnli_steps_per_second': 19.612, 'epoch': 1.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.30384892225265503, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5455, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.729, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.573, 'epoch': 2.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.575789213180542, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5166, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.951, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.595, 'epoch': 2.0}\n","{'eval_mnli_loss': 1.1827946901321411, 'eval_mnli_accuracy': 0.5183801554094442, 'eval_mnli_frac_non_target_tokens': 0.002390914524805738, 'eval_mnli_runtime': 34.0754, 'eval_mnli_samples_per_second': 196.388, 'eval_mnli_steps_per_second': 19.662, 'epoch': 2.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.3547651469707489, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4689, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.318, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.632, 'epoch': 3.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.4155762195587158, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.488, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.171, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.617, 'epoch': 3.0}\n","{'eval_mnli_loss': 1.080576777458191, 'eval_mnli_accuracy': 0.5195756126718469, 'eval_mnli_frac_non_target_tokens': 0.0008965929468021519, 'eval_mnli_runtime': 34.0665, 'eval_mnli_samples_per_second': 196.44, 'eval_mnli_steps_per_second': 19.667, 'epoch': 3.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.1906374841928482, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5354, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.807, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.581, 'epoch': 4.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.9859554767608643, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4987, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.089, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.609, 'epoch': 4.0}\n","{'eval_mnli_loss': 1.210363507270813, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.00014943215780035862, 'eval_mnli_runtime': 34.1244, 'eval_mnli_samples_per_second': 196.106, 'eval_mnli_steps_per_second': 19.634, 'epoch': 4.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.28482308983802795, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4591, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.393, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.639, 'epoch': 5.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.5738825798034668, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5139, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.971, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.597, 'epoch': 5.0}\n","{'eval_mnli_loss': 1.0251057147979736, 'eval_mnli_accuracy': 0.5204722056186492, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1027, 'eval_mnli_samples_per_second': 196.231, 'eval_mnli_steps_per_second': 19.647, 'epoch': 5.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.23767255246639252, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5021, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.062, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.606, 'epoch': 6.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.721997857093811, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5061, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.032, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.603, 'epoch': 6.0}\n","{'eval_mnli_loss': 1.0334571599960327, 'eval_mnli_accuracy': 0.5200239091452481, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1609, 'eval_mnli_samples_per_second': 195.897, 'eval_mnli_steps_per_second': 19.613, 'epoch': 6.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.21698899567127228, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5194, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.929, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.593, 'epoch': 7.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.8227927684783936, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5752, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.502, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.55, 'epoch': 7.0}\n","{'eval_mnli_loss': 1.1022621393203735, 'eval_mnli_accuracy': 0.5197250448296473, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1889, 'eval_mnli_samples_per_second': 195.736, 'eval_mnli_steps_per_second': 19.597, 'epoch': 7.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.17680864036083221, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4948, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.119, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.612, 'epoch': 8.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.009567975997925, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5024, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.06, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.606, 'epoch': 8.0}\n","{'eval_mnli_loss': 1.1323051452636719, 'eval_mnli_accuracy': 0.5195756126718469, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1592, 'eval_mnli_samples_per_second': 195.906, 'eval_mnli_steps_per_second': 19.614, 'epoch': 8.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.1700170636177063, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4945, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.12, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.612, 'epoch': 9.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.169278860092163, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5373, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.792, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.579, 'epoch': 9.0}\n","{'eval_mnli_loss': 1.1551791429519653, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1384, 'eval_mnli_samples_per_second': 196.026, 'eval_mnli_steps_per_second': 19.626, 'epoch': 9.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.23841288685798645, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5008, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.072, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.607, 'epoch': 10.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.9359421730041504, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4918, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.141, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.614, 'epoch': 10.0}\n","{'eval_mnli_loss': 1.1322790384292603, 'eval_mnli_accuracy': 0.5194261805140467, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1391, 'eval_mnli_samples_per_second': 196.022, 'eval_mnli_steps_per_second': 19.626, 'epoch': 10.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.38342660665512085, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5037, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.05, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.605, 'epoch': 11.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.6279116868972778, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4954, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.114, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.611, 'epoch': 11.0}\n","{'eval_mnli_loss': 1.074225902557373, 'eval_mnli_accuracy': 0.523311416616856, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1769, 'eval_mnli_samples_per_second': 195.805, 'eval_mnli_steps_per_second': 19.604, 'epoch': 11.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.4481249153614044, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5648, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.582, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.558, 'epoch': 12.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.5874285697937012, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5964, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.34, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.534, 'epoch': 12.0}\n","{'eval_mnli_loss': 1.096824049949646, 'eval_mnli_accuracy': 0.5228631201434548, 'eval_mnli_frac_non_target_tokens': 0.00014943215780035862, 'eval_mnli_runtime': 34.2552, 'eval_mnli_samples_per_second': 195.357, 'eval_mnli_steps_per_second': 19.559, 'epoch': 12.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.6304672956466675, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5432, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.747, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.575, 'epoch': 13.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.6322633028030396, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5577, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.636, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.564, 'epoch': 13.0}\n","{'eval_mnli_loss': 1.2724804878234863, 'eval_mnli_accuracy': 0.5234608487746563, 'eval_mnli_frac_non_target_tokens': 0.0034369396294082486, 'eval_mnli_runtime': 34.1509, 'eval_mnli_samples_per_second': 195.954, 'eval_mnli_steps_per_second': 19.619, 'epoch': 13.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.9520756006240845, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9966, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4797, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.234, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.623, 'epoch': 14.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.4612245559692383, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0056, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5963, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.34, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.534, 'epoch': 14.0}\n","{'eval_mnli_loss': 1.2718944549560547, 'eval_mnli_accuracy': 0.5511057979677226, 'eval_mnli_frac_non_target_tokens': 0.0038852361028093247, 'eval_mnli_runtime': 34.0929, 'eval_mnli_samples_per_second': 196.287, 'eval_mnli_steps_per_second': 19.652, 'epoch': 14.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.8930027484893799, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.421, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.688, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.669, 'epoch': 15.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.5551573038101196, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4747, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.273, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.627, 'epoch': 15.0}\n","{'eval_mnli_loss': 1.2628605365753174, 'eval_mnli_accuracy': 0.5310818888224746, 'eval_mnli_frac_non_target_tokens': 0.0014943215780035865, 'eval_mnli_runtime': 34.0722, 'eval_mnli_samples_per_second': 196.406, 'eval_mnli_steps_per_second': 19.664, 'epoch': 15.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.8804572224617004, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4238, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.666, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.667, 'epoch': 16.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.5235801935195923, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5489, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.703, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.57, 'epoch': 16.0}\n","{'eval_mnli_loss': 1.2536944150924683, 'eval_mnli_accuracy': 0.523759713090257, 'eval_mnli_frac_non_target_tokens': 0.0019426180514046623, 'eval_mnli_runtime': 34.3595, 'eval_mnli_samples_per_second': 194.764, 'eval_mnli_steps_per_second': 19.5, 'epoch': 16.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.8412193655967712, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9998, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5765, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.492, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.549, 'epoch': 17.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.241319179534912, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0008, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5319, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.834, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.583, 'epoch': 17.0}\n","{'eval_mnli_loss': 1.0893884897232056, 'eval_mnli_accuracy': 0.5280932456664674, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1155, 'eval_mnli_samples_per_second': 196.157, 'eval_mnli_steps_per_second': 19.639, 'epoch': 17.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.5413036346435547, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4973, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.099, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.61, 'epoch': 18.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.58274507522583, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4731, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.286, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.629, 'epoch': 18.0}\n","{'eval_mnli_loss': 1.0678774118423462, 'eval_mnli_accuracy': 0.5197250448296473, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.112, 'eval_mnli_samples_per_second': 196.177, 'eval_mnli_steps_per_second': 19.641, 'epoch': 18.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.43182533979415894, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.517, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.948, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.595, 'epoch': 19.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.621315836906433, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4657, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.342, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.634, 'epoch': 19.0}\n","{'eval_mnli_loss': 1.006476640701294, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1163, 'eval_mnli_samples_per_second': 196.153, 'eval_mnli_steps_per_second': 19.639, 'epoch': 19.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.38438716530799866, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4735, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.283, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.628, 'epoch': 20.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.8492422103881836, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4936, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.127, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.613, 'epoch': 20.0}\n","{'eval_mnli_loss': 1.0783653259277344, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1071, 'eval_mnli_samples_per_second': 196.206, 'eval_mnli_steps_per_second': 19.644, 'epoch': 20.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.3433646857738495, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4788, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.242, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.624, 'epoch': 21.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.7458741664886475, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4795, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.236, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.624, 'epoch': 21.0}\n","{'eval_mnli_loss': 1.0430594682693481, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.3836, 'eval_mnli_samples_per_second': 194.628, 'eval_mnli_steps_per_second': 19.486, 'epoch': 21.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.31177300214767456, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.6188, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.169, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.517, 'epoch': 22.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.8237252235412598, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5481, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.709, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.571, 'epoch': 22.0}\n","{'eval_mnli_loss': 1.051496148109436, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.218, 'eval_mnli_samples_per_second': 195.569, 'eval_mnli_steps_per_second': 19.58, 'epoch': 22.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.2571929693222046, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5266, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.874, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.587, 'epoch': 23.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 1.9134613275527954, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5079, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.018, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.602, 'epoch': 23.0}\n","{'eval_mnli_loss': 1.0481685400009155, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1178, 'eval_mnli_samples_per_second': 196.144, 'eval_mnli_steps_per_second': 19.638, 'epoch': 23.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.2087530791759491, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4947, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.119, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.612, 'epoch': 24.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.227717638015747, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.492, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.14, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.614, 'epoch': 24.0}\n","{'eval_mnli_loss': 1.1691182851791382, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1438, 'eval_mnli_samples_per_second': 195.994, 'eval_mnli_steps_per_second': 19.623, 'epoch': 24.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.14822006225585938, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5504, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.691, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.569, 'epoch': 25.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.5063915252685547, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5257, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.881, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.588, 'epoch': 25.0}\n","{'eval_mnli_loss': 1.2700366973876953, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.0707, 'eval_mnli_samples_per_second': 196.415, 'eval_mnli_steps_per_second': 19.665, 'epoch': 25.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.14638204872608185, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.505, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.04, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.604, 'epoch': 26.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.400230884552002, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4936, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.128, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.613, 'epoch': 26.0}\n","{'eval_mnli_loss': 1.2435659170150757, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1495, 'eval_mnli_samples_per_second': 195.962, 'eval_mnli_steps_per_second': 19.62, 'epoch': 26.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.1409006416797638, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4929, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.133, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.613, 'epoch': 27.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.403663396835327, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4897, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.158, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.616, 'epoch': 27.0}\n","{'eval_mnli_loss': 1.250723123550415, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.2018, 'eval_mnli_samples_per_second': 195.662, 'eval_mnli_steps_per_second': 19.59, 'epoch': 27.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.12907493114471436, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.479, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.24, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.624, 'epoch': 28.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.5673320293426514, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4916, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.143, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.614, 'epoch': 28.0}\n","{'eval_mnli_loss': 1.2853535413742065, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1287, 'eval_mnli_samples_per_second': 196.081, 'eval_mnli_steps_per_second': 19.632, 'epoch': 28.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.10797346383333206, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4829, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.21, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.621, 'epoch': 29.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.732008695602417, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4972, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.1, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.61, 'epoch': 29.0}\n","{'eval_mnli_loss': 1.3593757152557373, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1698, 'eval_mnli_samples_per_second': 195.845, 'eval_mnli_steps_per_second': 19.608, 'epoch': 29.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.10654953867197037, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4909, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.149, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.615, 'epoch': 30.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.6757757663726807, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5166, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.951, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.595, 'epoch': 30.0}\n","{'eval_mnli_loss': 1.340919852256775, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1633, 'eval_mnli_samples_per_second': 195.883, 'eval_mnli_steps_per_second': 19.612, 'epoch': 30.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.08147653192281723, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4877, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.173, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.617, 'epoch': 31.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.0279698371887207, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4995, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.082, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.608, 'epoch': 31.0}\n","{'eval_mnli_loss': 1.5102778673171997, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1202, 'eval_mnli_samples_per_second': 196.13, 'eval_mnli_steps_per_second': 19.636, 'epoch': 31.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.09919364750385284, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4957, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.111, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.611, 'epoch': 32.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.785259485244751, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.49, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.156, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.616, 'epoch': 32.0}\n","{'eval_mnli_loss': 1.410305142402649, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1588, 'eval_mnli_samples_per_second': 195.908, 'eval_mnli_steps_per_second': 19.614, 'epoch': 32.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.08600854128599167, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.4786, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.243, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.624, 'epoch': 33.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 2.9433906078338623, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.4717, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.297, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.63, 'epoch': 33.0}\n","{'eval_mnli_loss': 1.4818977117538452, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1118, 'eval_mnli_samples_per_second': 196.179, 'eval_mnli_steps_per_second': 19.641, 'epoch': 33.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.07543173432350159, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.6662, 'eval_hans-lexical_overlap-entailment_samples_per_second': 194.809, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.481, 'epoch': 34.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.0638067722320557, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.6593, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 194.861, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.486, 'epoch': 34.0}\n","{'eval_mnli_loss': 1.506327509880066, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.2367, 'eval_mnli_samples_per_second': 195.462, 'eval_mnli_steps_per_second': 19.57, 'epoch': 34.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.07934267818927765, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5439, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.741, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.574, 'epoch': 35.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.011241912841797, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5701, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.541, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.554, 'epoch': 35.0}\n","{'eval_mnli_loss': 1.4870284795761108, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1587, 'eval_mnli_samples_per_second': 195.909, 'eval_mnli_steps_per_second': 19.614, 'epoch': 35.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.07058566808700562, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5, 'eval_hans-lexical_overlap-entailment_samples_per_second': 196.078, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.608, 'epoch': 36.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.150460958480835, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5445, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.737, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.574, 'epoch': 36.0}\n","{'eval_mnli_loss': 1.5514882802963257, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.2236, 'eval_mnli_samples_per_second': 195.538, 'eval_mnli_steps_per_second': 19.577, 'epoch': 36.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.06785449385643005, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5363, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.8, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.58, 'epoch': 37.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.1985116004943848, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5512, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.685, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.569, 'epoch': 37.0}\n","{'eval_mnli_loss': 1.5742090940475464, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.184, 'eval_mnli_samples_per_second': 195.764, 'eval_mnli_steps_per_second': 19.6, 'epoch': 37.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.0714874118566513, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5249, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.887, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.589, 'epoch': 38.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.145799160003662, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5372, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.793, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.579, 'epoch': 38.0}\n","{'eval_mnli_loss': 1.5384503602981567, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1703, 'eval_mnli_samples_per_second': 195.843, 'eval_mnli_steps_per_second': 19.608, 'epoch': 38.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.06797046214342117, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.5313, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.838, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.584, 'epoch': 39.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.192810535430908, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5029, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 196.056, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.606, 'epoch': 39.0}\n","{'eval_mnli_loss': 1.5579659938812256, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1546, 'eval_mnli_samples_per_second': 195.933, 'eval_mnli_steps_per_second': 19.617, 'epoch': 39.0}\n","{'eval_hans-lexical_overlap-entailment_loss': 0.06626802682876587, 'eval_hans-lexical_overlap-entailment_accuracy': 1.0, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 25.526, 'eval_hans-lexical_overlap-entailment_samples_per_second': 195.879, 'eval_hans-lexical_overlap-entailment_steps_per_second': 19.588, 'epoch': 40.0}\n","{'eval_hans-lexical_overlap-contradiction_loss': 3.230205774307251, 'eval_hans-lexical_overlap-contradiction_accuracy': 0.0, 'eval_hans-lexical_overlap-contradiction_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-contradiction_runtime': 25.5403, 'eval_hans-lexical_overlap-contradiction_samples_per_second': 195.769, 'eval_hans-lexical_overlap-contradiction_steps_per_second': 19.577, 'epoch': 40.0}\n","{'eval_mnli_loss': 1.5761549472808838, 'eval_mnli_accuracy': 0.5198744769874477, 'eval_mnli_frac_non_target_tokens': 0.0, 'eval_mnli_runtime': 34.1432, 'eval_mnli_samples_per_second': 195.998, 'eval_mnli_steps_per_second': 19.623, 'epoch': 40.0}\n","{'train_runtime': 4364.3228, 'train_samples_per_second': 1.173, 'train_steps_per_second': 0.293, 'train_loss': -0.09233940243721009, 'epoch': 40.0}\n","***** train metrics *****\n","  epoch                    =       40.0\n","  train_loss               =    -0.0923\n","  train_runtime            = 1:12:44.32\n","  train_samples            =        128\n","  train_samples_per_second =      1.173\n","  train_steps_per_second   =      0.293\n"]}]}]}